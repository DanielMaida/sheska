Stacked transfer learning for tropical cyclone
intensity prediction
Ratneel Deo, Rohitash Chandra, and Anuraganand Sharma
1 School of Computing Information and Mathematical Science
University of the South Pacific, Suva, Fiji
http://www.usp.ac.fj
2 Centre for Translational Data Science
The University of Sydney, Sydney NSW, Australia
http://sydney.edu.au/data-science/
Abstract. Tropical cyclone wind-intensity prediction is a challenging
task considering drastic changes climate patterns over the last few decades.
In order to develop robust prediction models, one needs to consider dif-
ferent characteristics of cyclones in terms of spatial and temporal charac-
teristics. Transfer learning incorporates knowledge from a related source
dataset to compliment a target datasets especially in cases where there
is lack or data. Stacking is a form of ensemble learning focused for im-
proving generalization that has been recently used for transfer learning
problems which is referred to as transfer stacking. In this paper, we
employ transfer stacking as a means of studying the effects of cyclones
whereby we evaluate if cyclones in different geographic locations can
be helpful for improving generalization performance. Moreover, we use
conventional neural networks for evaluating the effects of duration on
cyclones in prediction performance. Therefore, we develop an effective
strategy that evaluates the relationships between different types of cy-
clones through transfer learning and conventional learning methods via
neural networks.
1 Introduction
Ensemble learning generally considers combination of multiple standalone learn-
ing methods to improve generalization performance when compared to stan-
dalone approaches [29]. Ensemble learning has been implemented with group
of neural networks that are trained as an ensemble with different configuration
in parameter settings or initializations for executing the same task[27, 12]. Pop-
ular methods in ensemble learning involve stacking, bagging and boosting [2,
8, 28] . Stacked generalization is a form of ensemble learning where the pre-
dictions are combined from the other ensembles. The principal idea in stacked
generalization is that more learners would improve performance due the addi-
tional computational power. [29]. In the literature, logistic regression has been
commonly used as the combiner layer for stacking [4]. Stacking has been suc-
cessfully used with both supervised and unsupervised learning [25, 4]. Recently,
ar
X
iv
:1
70
8.
06
53
9v
1 
 [
cs
.L
G
] 
 2
2 
A
ug
 2
01
7
2 Ratneel Deo, Rohitash Chandra, Anuraganand Sharma
the approach has been applied to modifying emission kinetics of colloidal semi-
conductor nanoplatelets[10].
Transfer learning utilizes knowledge learned previously from related problems
into learning models in order to have faster training or better or generalization
performance [19]. Transfer learning incorporates knowledge from a related prob-
lems (also known as source) to compliment a target problem especially in cases
where there is lack of data or in cases where there is requirement to speed up the
learning process. The approach has seen widespread applications with challenges
on the type of knowledge should be transferred in order to avoid negative trans-
fers whereby the knowledge deteriorates the performance [20, 22, 15]. Transfer
Learning has recently been used for visual tracking, computer-aided detection
[11, 24] . Transfer learning has been implemented with ensemble learning meth-
ods such as boosting and stacking [20]. The approach in the case of transfer
stacking is implementing multiple learners previously trained on the source data
in order to have a single base learner. Simple stacking on the other hand uses
multiple base learners[20].
Tropical cyclone wind-intensity prediction is a challenging task considering
drastic changes climate patterns over the last few decades [9, 17, 3] . Previously,
statistical models have been used to forecast the movement and intensity of
the cyclones. Climatology and Persistence (CLIPER) was one of the earlier
computer-based forecasting models which was able to give up to 5 days pre-
diction, i.e., 72 hours of cyclone intensity [14]. Statistical hurricane intensity
prediction scheme (SHIPS) was also used for cyclone intensity forecasts how-
ever, it was restricted to storms over the ocean only [16]. There has been a
growing interest in computational intelligence and machine learning methods
for cyclone prediction [13, 23, 21]. In the past, cyclone wind-intensity [5] been
tackled by cooperative neuro-evolution of recurrent neural networks[7, 6].
In order to develop robust prediction models, one needs to consider different
characteristics of cyclones in terms of spatial and temporal characteristics. Trans-
fer learning can be used as a strategy to evaluate the relationship of cyclones
from different geographic regions. Note that a negative transfer is considered
when the source knowledge when utilized with the target data contributes to
poor generalization. This can be helpful in evaluating if the cyclones from a par-
ticular region is helpful in guiding as source knowledge for decision making by
models in other geographic locations. Moreover, it is also important to evaluate
the effect of the duration of a cyclone on the generalization performance given
by the model.
In this paper, we employ transfer stacking as a means of studying the effects
of cyclones whereby we evaluate if cyclones in different geographic locations can
be helpful for improving generalization performs. We select the cyclones from last
few decades in the South Pacific and South Indian Oceans. Firstly, we evaluate
the performance of the standard neural networks when trained with different
regions of the dataset. We then evaluate the effects on duration of the cyclones
in the South Pacific region and their contribution towards the neural networks
generalization performance. Finally, we use transfer staking via ensembles and
Stacked transfer learning for tropical cyclone intensity prediction 3
consider the South Pacific region as the target model. We use South Indian
Ocean as the source data and evaluate its impact on the South Pacific Ocean.
The backpropagation neural network is used as the stacked ensembles in the
transfer stacking method.
The rest of the paper is organized as follows. Section 2 presents the overview
of transfer stacking method and outlines the experimental setup. We discuss our
experimental results in Section 3 and conclude with directions for future research
in Section 4.
2 Methodology
2.1 Neural networks for time series prediction
Time series are data of a series of events observed over a certain time period. In
order to use neural networks for time series prediction, the original time series
is reconstructed into a state-space vector with embedding dimension (D) and
time-lag (T) through Taken’s theorem [26] . We consider the backpropagation
algorithm which employs gradient descent for training [18]. A feedforward neural
network is defined by:
E(yt) = g
(
?o +
H?
h=1
vjg
(
?h +
D?
d=1
wdhyt?d)
)
(1)
where ?o and ?h are the bias weights for the output o and hidden h layer,
respectively. Vj is the weight which maps the hidden layer h to the output layer.
wdh is the weight which maps yt?d to the hidden layer h and g is the activation
function, which we assume to be a sigmoid function for the hidden and output
layer units.
The root mean squared error which is generally used to test the performance
of the FNN in given in equation 2.
RMSE =
???? 1
N
N?
i=1
(yi ? y?i)2 (2)
where yi and y?i are the observed and predicted data, respectively. N is the length
of the observed data.
2.2 Stacked transfer learning
Transfer learning is implemented via stacked ensembles which form source and
target ensemble and a combiner ensemble that are implemented using feedfor-
ward neural networks (FNNs). Enemble 1,2 and the combiner network in figure
1 show the FNNs . We refer to the transfer learning model shown in figure 1
as transfer stacking hereafter. Transfer stacking is implemented in two phases;
phase one involves training individual ensembles from the network. The second
4 Ratneel Deo, Rohitash Chandra, Anuraganand Sharma
phase of the method trains a secondary prediction model which learns from the
knowledge of the trained ensembles in phase 1. Figure 1 shows the broader view
of the ensemble stacking method where we have two ensemble models (FNNs)
feeding knowledge into a secondary combiner network. The source and target
ensembles are implemented using FNNs with the same topology. The combiner
ensemble topology is depended on the number of ensembles used as the source
and target ensembles. Ensemble 1 considers the South Pacific ocean data while
Ensemble 2 considers the South Indian ocean training data. The datasets are
described in section 2.3.
Fig. 1. Neural Network Ensemble Model
The combiner ensemble is a feedforward network that is trained on the knowl-
edge processed by the ensembles. Backpropagation is used for training the com-
biner network and the respective ensembles. The processed knowledge comes
from training data of the source and target data. Knowledge was gathered from
creating a stacked dataset that is a direct mapping from the training data. This
was achieved by concatenating the output of all the ensembles into a new stacked
data file. The stacked dataset encompassing the knowledge of the ensembles is
then used to train the combiner FNN network.
Similar to the two step training process, the testing done in two phases. The
testing data was also passed through the stacking module to generate a stacked
testing data. The stacked testing data was then used in the combiner network
to measure the generalization performance of transfer stacking .
2.3 Data Processing
The South Pacific ocean cyclone wind intensity data and South Indian Ocean
cyclone wind intensity data for the year 1985 to 2013 had been used for these
experiments[1]. We divided the data into training and testing sets. Cyclones
occurring in the years 1985 to 2005 were used for training while the remaining
Stacked transfer learning for tropical cyclone intensity prediction 5
data was used to test for generalization performance. The consecutive cyclones
in the training and testing set was concatenated into a time series for effective
modeling. The data was normalized to be in the range [ 0, 1].
3 Experiments and Results
In this section, we present the experiments that we had used to test the transfer
stacking for cyclone intensity prediction. We later present our results based on
the root mean squared error.
3.1 Experiment Design
Standalone feed forward neural networks that were trained using the same back
propagation learning algorithm used in the experiments. Stochastic gradient de-
scent was used with 2000 epochs training time. 30 experimental runs of each of
the experiments was done in order to provide mean performance. The experi-
ments were designed as presented in the list.
1. Experiment 1: Vanilla FNN trained on all South Pacific ocean training data
and tested on South Pacific Ocean testing data.
2. Experiment 2: Vanilla FNN trained on all Indian ocean training data and
tested on South Pacific Ocean testing data.
3. Experiment 3: 6 experiments with vanilla FNNs trained on subset of South
Pacific ocean training data and tested twice. Once with the entire South
Pacific Ocean testing data followed by the testing with a subset of the testing
data . The subsets were created by grouping cyclones of similar lengths into
classes. Each class of cyclones had been trained and tested with vanilla FNN
model. We formulated the following experiments with vanilla FNNs;
(a) [0? 3] day old cyclones in training set and tested with full testing set as
well as [0 ? 3 day old cyclones in testing set.
(b) [3? 5] day old cyclones in training set and tested with full testing set as
well as [3 ? 5] day old cyclones in testing set.
(c) [5? 7] day old cyclones in training set and tested with full testing set as
well as [5 ? 7] day old cyclones in testing set.
(d) [7? 9] day old cyclones in training set and tested with full testing set as
well as [7 ? 9] day old cyclones in testing set.
(e) [9 ? 12] day old cyclones in training set and tested with full testing set
as well as [9 ? 12] day old cyclones in testing set.
(f) cyclones older than 12 days in training set and tested with full testing
set as well as cyclones older than 12 day in testing set.
4. Experiment 4: Transfer learning based stacked ensemble method for pre-
dicting South Pacific ocean tropical cyclone intensity. The mechanics of this
method is given in section 2.2.
5. Experiment 5: Two separate experiments were done in this experiment;
(a) FNN trained on 1985 - 1995 cyclones from south pacific data and tested
on South Pacific Ocean testing data.
(b) FNN trained on 1995 - 2005 cyclones from south pacific data and tested
on South Pacific Ocean testing data.
6 Ratneel Deo, Rohitash Chandra, Anuraganand Sharma
3.2 Results
We present the results of the prediction of tropical cyclones intensity in the
South Pacific form the year 2006 to 2013. The root mean squared error (RMSE)
was used to evaluate the performance as given in equation 2.
Table 1. Generalization performance
Experiment RMSE
1 0.02863 ± 0.00042
2 0.03396 ± 0.00075
4 0.02802 ± 0.00039
Table 1 gives the generalization performance of the respective methods on
the testing data. The results show that all the models have similar performance.
It looks at results from experiments 1, 2 and 4.
Table 2. Experiment 3: Performance of FNN on different categories of cyclones
Cyclone Category Training RMSE Categorical Testing RMSE Generalization RMSE
0-3 day 0.03932 ± 0.00173 0.05940 ± 0.00329 0.20569 ± 0.01339
3-5 day 0.03135 ± 0.00050 0.02580 ± 0.00044 0.05200 ± 0.00532
5-7 day 0.03265 ± 0.00027 0.02504 ± 0.00025 0.03070 ± 0.00172
7-9 day 0.02831 ± 0.00033 0.03799 ± 0.00065 0.03207 ± 0.00055
9-12 day 0.03081 ± 0.00025 0.02700 ± 0.00059 0.03154 ± 0.00047
± 12 day 0.02819 ± 0.00019 0.03579 ± 0.00037 0.02875 ± 0.00025
Table 2 gives the performance of various categories of data on the two testing
datasets; category based testing and generalized testing. Category based testing
is done on cyclones that belong that particular category of the testing data.
Generalization testing was done on the entire testing dataset. The results show
that cyclones that ended in under three days were not good predictors for the
generalization data as they had higher testing error. Similarly, cyclones that had
duration of 3-5 days had poor performance as well giving a larger error however
not as large as is predecessor.
Cyclones with duration of 5-12 days had very similar generalization perfor-
mance. These categories of cyclones performed better than the smaller length cy-
clones by giving better prediction accuracy in terms of RMSE. The final category
of cyclones gave the best generalization performance. Longer length cyclones, 12
days and over was matching the prediction accuracy of the best models that
is, the standalone FNN model of control experiment 1, periodical and spatial
analysis ensemble models.
Table 3 shows the generalization performance achieved by the standalone
FNN model trained with the decade 1 and decade 2 training data. The general-
Stacked transfer learning for tropical cyclone intensity prediction 7
Table 3. Experiment 5: Performance of Vanilla FNN on independent decade training
data
Vanilla FNN Training RMSE Testing RMSE
1985 - 1995 cyclones 0.04434 ± 0.00073 0.04671 ± 0.00209
1995 - 2005 cyclones 0.03635 ± 0.00062 0.05949 ± 0.00201
ization performance is rather poor with both the decades of data used indepen-
dently when compared to the concatenation of all the training data as seen in
experiment 1.
3.3 Discussion
The experiments revealed interesting results about the respective experiments.
The first two experiments considered conventional learning through neural net-
works (FNN) for predicting tropical cyclone wind intensity. Experiments 1 con-
sidered cyclones where the training and testing dataset from the same region
(South Pacific ocean) was used. Experiment 2 considered cyclones where train-
ing data from South Indian ocean and testing data from South Pacific ocean
was used. According to the results, there was minimal difference in the general-
ization performance in the South Pacific ocean, although the training datasets
considered different regions. This implies that the cyclones in the South Indian
ocean have similar characteristics in terms of the change of wind-intensity when
compared to South Pacific ocean. Note that the size of the South Indian ocean
dataset was about three times larger when compared to South Pacific ocean.
Furthermore, Experiment 3 featured an investigation into the effects of the
duration of cyclones (cyclone lifetime) on the generalization performance. This
was done only for the case of the South Pacific ocean. Note that the generaliza-
tion performance is based on the test dataset that includes all the different types
of cyclones that occurred between year 2006 to year 2013. As seen in the results,
cyclones with shorter durations were not effective when considering the general-
ization performance. It seems that the shorter duration of the cyclones did not
give enough information to feature essential knowledge for the longer duration of
cyclones in the test dataset. The category with the cyclones with longest lengths
gave the best performance in terms of generalization performance .This implied
that it had known about all the phases of the life cycle of the cyclone, thus it
was able to effectively predict all classes of cyclones.
Transfer stacking via neural network ensembles was done in Experiment 4
where training dataset from South Indian ocean was used as source datasets and
cyclones in the South Pacific Ocean was used in the target datasets. The gen-
eralization performance here was similar to conventional neural networks given
Experiment 1 and 2. This shows that the source data (South Indian ocean) did
not make significant contributions towards improving the generalization perfor-
mance, however, we note that there was not a negative transfer of knowledge
as the performance was not deteriorated. Therefore, the knowledge from the cy-
clone behavior or change in wind-intensity Indian ocean is valid and applicable
8 Ratneel Deo, Rohitash Chandra, Anuraganand Sharma
for South Pacific ocean. Further validation can be done in future through exam-
ining the track information of the cyclones from the respective regions. This will
add further insights of transfer learning through stacking and establish better
knowledge about the relationship of the cyclones in the respective regions.
4 Conclusion
The paper presented transfer stacking as a means of studying the contribution
of cyclones in different geographic locations for improving generalization perfor-
mance in predicting tropical cyclone wind intensity for the South Pacific ocean.
We then evaluated the effects on duration of the cyclones in the South Pacific
region and their contribution towards the neural networks generalization perfor-
mance. Cyclone duration was seen to be a major contributor in the prediction
of cyclone intensity.
We found that cyclones with duration of over 12 days could be used as good
representative for training the neural networks with competitive prediction in-
tensity. Furthermore, the results show that the Indian Ocean source dataset
does not significantly improve the generalization performance of the South Pa-
cific target problem in terms of generalization performance. The contributions
of the Indian ocean data was negligible as the knowledge about cyclone intensity
prediction was sufficiently learned from the South Pacific data. The change in
geographical location was unable to provide any new knowledge which would
improve generalization.
Further work can review other cyclone regions into the transfer learning
methodology to further improve the generalization performance. The approach
can be extended to prediction of cyclone tracks in the related regions. Recur-
rent neural networks (RNN) could be used as ensemble learners to identify any
temporal sequences that FNN was unable to learn as RNNs have shown better
modeling performance. Hybrid ensemble models of neural networks could also
be developed that use evolutionary algorithms for training the FNN together
with backpropagation to improve the modeling.
References
1. JTWC tropical cyclone best track data site (2015), \url{http://www.usno.navy.
mil/NOOC/nmfc-ph/RSS/jtwc/}
2. Bauer, E., Kohavi, R.: An empirical comparison of voting classification algorithms:
Bagging, boosting, and variants. Machine learning 36(1), 105–139 (1999)
3. Bennett, A., Leslie, L., Hagelberg, C., Powers, P.: Tropical cyclone prediction using
a barotropic model initialized by a generalized inverse method. Monthly Weather
Review 121(6), 1714–1729 (1993)
4. Breiman, L.: Stacked regressions. Machine learning 24(1), 49–64 (1996)
5. Chandra, R., Dayal, K.: Cooperative coevolution of Elman recurrent networks
for tropical cyclone wind-intensity prediction in the South Pacific region. In: IEEE
Congress on Evolutionary Computtaion. pp. 1784–1791. Sendai, Japan (May 2015)
Stacked transfer learning for tropical cyclone intensity prediction 9
6. Chandra, R., Deo, R., Omlin, C.W.: An architecture for encoding two-dimensional
cyclone track prediction problem in coevolutionary recurrent neural networks. In:
Neural Networks (IJCNN), 2016 International Joint Conference on. pp. 4865–4872.
IEEE (2016)
7. Deo, R., Chandra, R.: Identification of minimal timespan problem for recurrent
neural networks with application to cyclone wind-intensity prediction. In: Neural
Networks (IJCNN), 2016 International Joint Conference on. pp. 489–496. IEEE
(2016)
8. Drucker, H.: Improving regressors using boosting techniques. In: ICML. vol. 97,
pp. 107–115 (1997)
9. Emanuel, K.: Increasing destructiveness of tropical cyclones over the past 30 years.
Nature 436(7051), 686–688 (2005)
10. Erdem, O., Olutas, M., Guzelturk, B., Kelestemur, Y., Demir, H.V.: Temperature-
dependent emission kinetics of colloidal semiconductor nanoplatelets strongly mod-
ified by stacking. The journal of physical chemistry letters 7(3), 548–554 (2016)
11. Gao, J., Ling, H., Hu, W., Xing, J., et al.: Transfer learning based visual tracking
with gaussian processes regression. In: ECCV (3). pp. 188–203 (2014)
12. Hansen, L.K., Salamon, P.: Neural network ensembles. IEEE transactions on pat-
tern analysis and machine intelligence 12(10), 993–1001 (1990)
13. Jin, L., Yao, C., Huang, X.Y.: A nonlinear artificial intelligence ensemble prediction
model for typhoon intensity. Monthly Weather Review 136, 4541–4554 (2008)
14. Knaff, J.A., DeMaria, M., Sampson, C.R., Gross, J.M.: Statistical, five-day tropi-
cal cyclone intensity forecasts derived from climatology and persistence. Weather
Forecasting 18, 80–92 (2003)
15. Lawrence, N.D., Platt, J.C.: Learning to learn with the informative vector machine.
In: Proceedings of the twenty-first international conference on Machine learning.
p. 65. ACM (2004)
16. M., D., Kaplan, J.: An updated statistical hurricane intensity prediction scheme
(ships) for the atlantic and eastern north pacific basins. Weather Forecasting 14,
236 – 337 (1999)
17. Mu, M., Zhou, F., Wang, H.: A method for identifying the sensitive areas in tar-
geted observations for tropical cyclone prediction: Conditional nonlinear optimal
perturbation. Monthly Weather Review 137(5), 1623–1639 (2009)
18. Nevel’son, M.B., Khas’ minskii, R.Z.: Stochastic approximation and recursive es-
timation, vol. 47. American Mathematical Society Providence (1976)
19. Pan, S.J., Yang, Q.: A survey on transfer learning. IEEE Transactions on knowledge
and data engineering 22(10), 1345–1359 (2010)
20. Pardoe, D., Stone, P.: Boosting for regression transfer. In: Proceedings of the 27th
international conference on Machine learning (ICML-10). pp. 863–870 (2010)
21. Pham, B.T., Bui, D.T., Dholakia, M., Prakash, I., Pham, H.V.: A comparative
study of least square support vector machines and multiclass alternating decision
trees for spatial prediction of rainfall-induced landslides in a tropical cyclones area.
Geotechnical and Geological Engineering 34(6), 1807–1824 (2016)
22. Raina, R., Battle, A., Lee, H., Packer, B., Ng, A.Y.: Self-taught learning: transfer
learning from unlabeled data. In: Proceedings of the 24th international conference
on Machine learning. pp. 759–766. ACM (2007)
23. Rajasekaran, S., Gayathri, S., Lee, T.L.: Support vector regression methodology
for storm surge predictions. Ocean Engineering 35(16), 1578–1587 (2008)
24. Shin, H.C., Roth, H.R., Gao, M., Lu, L., Xu, Z., Nogues, I., Yao, J., Mollura, D.,
Summers, R.M.: Deep convolutional neural networks for computer-aided detection:
10 Ratneel Deo, Rohitash Chandra, Anuraganand Sharma
Cnn architectures, dataset characteristics and transfer learning. IEEE transactions
on medical imaging 35(5), 1285–1298 (2016)
25. Smyth, P., Wolpert, D.: Linearly combining density estimators via stacking. Ma-
chine Learning 36(1), 59–83 (1999)
26. Takens, F.: Detecting strange attractors in turbulence. In: Dynamical Systems and
Turbulence, Warwick 1980, pp. 366–381. Lecture Notes in Mathematics (1981)
27. Ueda, N.: Optimal linear combination of neural networks for improving classifica-
tion performance. IEEE Transactions on Pattern Analysis and Machine Intelligence
22(2), 207–215 (2000)
28. Wang, G., Hao, J., Ma, J., Jiang, H.: A comparative assessment of ensemble learn-
ing for credit scoring. Expert systems with applications 38(1), 223–230 (2011)
29. Wolpert, D.H.: Stacked generalization. Neural networks 5(2), 241–259 (1992)
