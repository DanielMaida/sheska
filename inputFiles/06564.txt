The Continuous Hint Factory - Providing
Hints in Vast and Sparsely Populated Edit
Distance Spaces
Benjamin Paaßen Barbara Hammer
CITEC center of excellence CITEC center of excellence
bpaassen@techfak.uni-bielefeld.de bhammer@techfak.uni-bielefeld.de
Thomas W. Price Tiffany Barnes
North Carolina State University North Carolina State University
twprice@ncsu.edu tmbarnes@ncsu.edu
Sebastian Gross Niels Pinkwart
Humboldt-Universität zu Berlin Humboldt-Universität zu Berlin
sebastian.gross@informatik.hu-berlin.de niels.pinkwart@hu-berlin.de
This is a preprint of a publication submitted to the Journal of
Educational Datamining at 2017-08-12 as provided by the
authors.
Abstract
Intelligent tutoring systems can support students in solving multi-
step tasks by providing a hint regarding what to do next. However,
engineering such next-step hints manually or using an expert model
becomes infeasible if the space of possible states is too large. Therefore,
several approaches have emerged to infer next-step hints automatically,
relying on past student’s data. Such hints typically have the form of
an edit which could have been performed by capable students in the
given situation, based on what past capable students have done. In
this contribution we provide a mathematical framework to analyze
edit-based hint policies and, based on this theory, propose a novel hint
1
ar
X
iv
:1
70
8.
06
56
4v
1 
 [
cs
.A
I]
  2
2 
A
ug
 2
01
7
Preprint as provided by the authors. 2
policy to provide edit hints for learning tasks with a vast state space
and sparse student data. We call this technique the continuous hint
factory because it embeds student data in a continuous space, in which
the most likely edit can be inferred in a probabilistic sense, similar to
the hint factory.
In our experimental evaluation we demonstrate that the continuous
hint factory can predict what capable students would do in solving a
multi-step programming task and that hints provided by the continu-
ous hint factory match to some extent the edit hints that human tutors
would have given in the same situation.
keywords: next-step hints, hint factory, edit distances, computer science
education, Gaussian Processes
1 Introduction
In many educational domains, learning tasks require more than a single step
to solve. For example, programming tasks require a student to iteratively
write, test and refine code that accomplishes a given objective [15, 39, 44].
When working on such multi-step-tasks, students start with an initial state
and then change their state by applying an action (such as inserting or delet-
ing a piece of code). At some point, a student may not know how to proceed
or may be unable to find an error in her current state, in which case external
help is required. In particular, such a student may benefit from a next-step
hint, guiding her toward a more complete and/or more correct version and
allowing her to continue working on her own [2]. Many intelligent tutoring
systems (ITS) support these multi-step tasks by generating next-step hints to
match the student’s current state and her underlying strategy [47]. Typically,
such hints are generated using an expert-crafted model. However, designing
such an expert model becomes infeasible if the space of possible states grows
too large [28, 20, 44]. This is the case for most computer programming tasks
because the space of possible programs grows exponentially with the program
length and the set of programs which generate the same function is infinite
[36]. Other examples are so-called ill-defined domains where explicit domain
knowledge is not available or at least very hard to formalize [25]. In this pa-
per, we address hint generations in these vast state spaces with a particular
focus on the domain of computer programming.
Preprint as provided by the authors. 3
Several approaches have emerged which provide next-step hints without
an expert model. Typically, these approaches provide hints in the form of
edits, that is, actions which can be applied to the student’s current state
to change it into a more correct and/or more complete state, based on the
edits that successful students in the past have applied [5, 16, 36, 38, 44, for
example]. Such edit-based next-step hints constitute an elegant and simple
approach to feedback for complex learning tasks. The most basic version of
the approach needs only two ingredients: an edit function, which is able to
compute the edits that are necessary to transform one state into a solution to
the task. If a student issues a help request, the system can simply compute
the necessary edits from the student’s state to the solution and use one of
these edits as a hint [50]. Even though this approach is fairly simple, it is
conceptually quite powerful, because the feedback provided is personalized in
the sense that the hint a student receives depends on her personal state and
is thereby tailored to her specific situation [23]. Another advantage is that
this approach needs very little task-specific work on the side of the teachers,
because they only need to construct one solution for the task, and can apply
a general-purpose edit function which is applicable across tasks or even across
domains [27].
In this contribution, we will embed existing edit-based hint approaches
into a common, mathematical framework, providing precise definitions for
key concepts in the field. A key part of this novel theory is the notion of the
edit distance space, a continuous space in which each state corresponds to one
vector and the distance between vectors corresponds exactly to the number
of edits it takes to get from one state to another one. This edit distance space
forms the basis for the continuous hint factory, a novel hint approach which
first infers the most likely edit in the edit distance space based on machine
learning techniques and then finds a human-readable edit which corresponds
to the recommendation in the edit distance space. This novel technique is a
general-purpose hint policy which can be applied whenever an edit distance
and some, possibly few, data of past students is available. Therefore, the
continuous hint factory provides a novel option for hint feedback in learning
tasks where little domain engineering is possible and little student data is
available. In a sense, we combine the probabilistic modelling of the hint fac-
tory, a well-established hint approach for densely populated state spaces [45],
with the nearest-neighbor-principle commonly used in hint policies for vast
and sparsely populated state spaces [16, 44, 50] to achieve a novel approach
that extends existing work. In experiments on two real-world datasets we
Preprint as provided by the authors. 4
demonstrate that the continuous hint factory is able to predict what capable
students would do in solving a learning task and that it can utilize these
predictions to provide hints which match what human tutors would have
recommended.
We begin our work by introducing precise definitions of key concepts
of edit-based hint policies and review existing approaches within this novel
framework. In section 3 we introduce the continuous hint factory based on
this framework and in section 4 we report on our experimental evaluation of
the continuous hint factory.
2 An integrated view of edit-based hint policies
In this section we review existing approaches to edit-based hint policies.
Alongside this review, we develop a mathematical theory of edit distances
and edit-based hint policies, which helps us to contextualize past approaches
and will form a firm basis for our own approach in the next section. First,
let us start with an example of a learning task, for which an edit-based hint
policy may be helpful. Consider the task of creating an activity diagram in
the unified modelling language (UML), which models a program that has two
inputs, m and n, and returns ?1 if m < n, 0 if m = n, and 1 if m > n. The
solution to this task is shown in Figure 1 on the left. In a tutoring system
including this task, the student starts off with an empty UML diagram, and
then applies edits to the diagram until she is stuck and does not know how
to proceed, for example in state x3 on the right. Then, she hits the “help”
button of the system and is provided with a suggestion for an edit she could
apply to get closer to a correct solution, for example to add the statement
“Let n be the second input” to her diagram.
From a pedagogic point of view, other kinds of hints may lead to better
learning gains compared to edit hints. In particular, edit hints lack the
capacity to reference underlying concepts which may be helpful for the task
or elaborate on these concepts, as suggested by Fleming and Levie [10, 22].
Instead, edit hints directly display the next step towards a more correct and
complete state. Aleven et al. suggest to display these “bottom-out hints”
hints only as a last resort after exhausting options for more principle-based
hints [2]. Indeed, the research they review suggests that principle-based hints
lead to higher learning gains compared to bottom-out hints. So, why do we
focus in this particular kind of hint?
Preprint as provided by the authors. 5
1
Let m be the first input2
Let n be the second input3
Initialize z = 04
5
z = 0
7
z = 1
6
z = ?1
8
9
Return z10
11
m > n
m = n
m < n
x1
1x2
1
Let m be the first input
2
x3
1
2
x4
1
Let m be the first input
2
Let n be the second input
3
x5
1
2
z = 03
m = n
x6
Figure 1: Left: An UML activity diagram representing a program with two
inputs, x and y, which returns ?1 if x < y, 0 if x = y and 1 if x > y. Right:
A small excerpt of the legal move graph for the UML activity diagram task
on the left.
Preprint as provided by the authors. 6
First, edit hints are different from other bottom-out hints in that they
display only a very small part of the solution (a single edit), allowing the
student to finish most of the problem independently. Second, bottom-out
hints, such as edit hints, may lead to learning gains, if students reflect on the
hint and engage in sense-making behavior [2]. Conversely, if students aim
to abuse the system, this is not hindered by principle-based hints: students
simply skip through them to reach the bottom-out hint [2]. Third, we point
to a study by Price et al. which indicates that edit hints are judged as relevant
and interpretable by human tutors [41]. Finally, and most importantly, we
argue that more elaborate hint strategies are simply not available in many
important learning tasks, because they require hint messages which result
from an expert-crafted model, which is infeasible if the space of possible states
is vast and includes many different strategies, because the sheer number of
different hint messages necessary is too large for human experts to handle
[28, 44, 23], or because human experts may overlook strategies that novices
might employ (“expert blind spot”) [29]. For such learning tasks, edit-based
hints may be the best form of feedback that is still applicable in practice.
For this reason, recent work on hint generation for programming has focused
largely on automatic, edit-based hint generation [16, 21, 38, 44, 50].
We note that there have been some approaches to make expert-crafted
hints available in larger state spaces. First, we highlight authoring tools
for tutoring systems, which aim at reducing the expert work that needs to
be put in to design feedback for individual tasks. A prime example are
the cognitive tutor authoring tools (CTAT) which support the construction
of cognitive tutors, in particular example-tracing tutors [1]. With regards to
intelligent tutoring systems, this can be seen as a “gold standard”, because the
effectiveness of cognitive tutors has been established in classroom studies, as
well as their successful application in classrooms across the US [20]. However,
even with authoring tools, covering the whole space of possible states may be
very challenging or even impossible for learning tasks with vast state spaces,
given that the upper end of complexity demonstrated by Aleven et al. is a
task with roughly 20 steps and 6 different paths toward the solution [1]. By
comparison, in our programming dataset, we observed that almost each of
the 47 solution attempts was unique and each of them involved more than
40 steps. Another approach is “force multiplication”, which assumes that a
relatively small number of expert-crafted hint messages are available, which
are then applied to new situations automatically, thereby “multiplying the
force” of expert work [35]. Examples include the work of Head et al., Yin et
Preprint as provided by the authors. 7
al., and Choudhury et al. who apply clustering methods to aggregate many
different states and then provide the same hint to all states in the same
cluster [18, 48, 7]. Another example is the work of Piech et al. who assume
that expert-crafted hints are annotated with example states for which the
given hint makes sense, and example states for which the given hint does
not make sense in the opinion of the experts. Then, they train a classifier
function via machine learning which decides for any new state whether the
hint should be displayed or not [35]. Finally, Marin et al. annotate expert-
crafted hints with small snippets of Java code for which the given hint makes
sense and display the hint whenever the respective snippet is discovered in a
student’s state [26]. Note that these approaches are limited by the number
of hints that are provided by the teaching experts. If for some situation no
hint is contained in the database, the system is not able to provide fitting
feedback.
In the remainder of this chapter we will analyze edit-based next-step
hint approaches in more detail. We will highlight key concepts, provide
precise definitions and shed some light on the theory behind edit-based hint
approaches. We start our investigation by defining edits, legal move graphs
and edit distances in a rigorous fashion. Second, we discuss techniques to
change our data representation in order to support meaningful hints. Third,
we incorporate student data in the form of traces and interaction networks.
Finally, we provide an overview of the different approaches that have emerged
in the literature and compare them in light of our mathematical framework.
2.1 Edit Distances and Legal Move Graphs
Remember that we want to support students in solving a multi-step learning
task by providing on-demand hints. In this scenario, a student starts with an
initial state provided by the system, and then successively edits this initial
state until she finishes or gets stuck and asks the system for help. To achieve
such a hint system, we first need to define the set of possible edits that
students can apply (the edit set). Then, we need to chain these edits to
find paths of edits that lead to a solution (the legal move graph). Finally,
we want to identify the shortest path toward a solution, which leads us to
the notion of edit distance. We begin by defining the edit set. Recall our
example of a UML activity diagram task. Figure 1 (right) shows how an
initially empty graph can be extended by different edits. Note that each
state in this figure is a UML diagram, and our edits manipulate diagrams
Preprint as provided by the authors. 8
to yield new diagrams. In this example, our edit set permits inserting new
nodes as successors of existing nodes, deleting nodes and re-labelling nodes
in the existing diagram. Note that edits differ depending on which node we
manipulate and which labels we consider. For example, inserting a start node
(the transition of x1 to x2) is different from inserting an action node (x2 to
x3), and inserting an action node after the start node (x2 to x3) is different
from inserting an action node after another action node (x3 to x5). Further
note that this edit set is symmetric, meaning that for every edit we apply we
can apply an inverse edit which undoes our previous edit. In general, we also
assume that our edit sets are reflexive, meaning that a “neutral” edit exists
which leaves the student’s state unchanged. These set properties are of key
importance to our later mathematical claims. The mathematical definition
of edits and edit sets is as follows:
Definition 1 (Edit Set). Let X be the set of all states for a learning task.
An edit on X is a function ? : X ? X. A set ? of edits on X is called
an edit set. We call an edit set reflexive if for all states x ? X there exists
an edit ? ? ?, Such that ?(x) = x. We call an edit set symmetric if for all
states x ? X and all edits ? ? ? there exists an edit ??1 ? ? such that
??1(?(x)) = x. We call ??1 the inverse edit for ? on x.
This concept of edits already permits us to define the problem we would
like to solve, namely to find a function which, for any state a student might
find herself in, returns an edit guiding her closer to a solution. Inspired by
Piech et al. we call such a function a hint policy [36].
Definition 2 (Hint Policy). Let X be a set and ? be an edit set on X. A
hint policy is a function ? : X ? ?.
Note that Piech et al. define a hint policy differently, namely as a function
?? mapping a state to a state the student should proceed to next. Our
definition is more general than theirs, in the sense that for every policy ?
according to our definition we can construct a Piech-style hint policy ?? by
simply setting ??(x) = ?(x) where ? = ?(x).
A simple example hint policy is the policy of Zimmerman and Rupakheti,
who suggest to return the first edit in the shortest sequence of edits which
transforms the input state to a correct solution for the task [50]. This shortest
sequence of edits can be viewed as a path in a legal move graph which has the
possible states X as nodes and the edits ? as edges. The precise definition
of this graph is as follows:
Preprint as provided by the authors. 9
Definition 3 (Legal Move Graph). Let X be a set and ? be an edit set
on X. Then, the legal move graph according to X and ? is defined as the
directed graph GX,? = (X,E) where E = {(x, y)|?? ? ? : ?(x) = y}.
An excerpt of the legal move graph for our UML example is shown in
Figure 1 (right). The legal move graph for this example can be constructed
as follows: First, start with a node representing an empty UML diagram (x1
in Figure 1 on the right). Then, recursively extend the legal move graph with
the following procedure: For all states x that we have already constructed,
consider the states y that result from adding, removing or relabelling a single
node to x, add y to the legal move graph (if not already present) and con-
nect x to y with a directed egde. Note that the legal move graph does not
only include states which lead toward the solution but also includes a lot of
erroneous or absurd states. For example, Figure 1 includes the states x4 and
x6 which add the decision node too early.
The notion of a shortest sequence of edits transforming a student’s state
x to a solution y now has a proper graph-theoretical interpretation: It is
the shortest path from x to y in the legal move graph. The length of this
shortest path can be seen as a distance d between x and y. As an example,
consider once more the legal move graph in Figure 1 (right). Here we find,
for example, d(x1, x2) = 1 and d(x1, x6) = 3.
We implicitly assumed that all edges in a legal move graph have the length
1. However, we can also consider edges with different lengths, which leads
us to the notion of an edit cost function and a more general concept of edit
distance:
Definition 4 (Edit Cost Function and Edit Distances). Let X be a set and
? be an edit set on X. A function C : ? × X ? R is called an edit cost
function on ?. We call C(?, x) the cost of applying edit ? to the state x.
We call an edit cost function non-negative if C(?, x) ? 0 for all states
X ? X and all edits ? ? ?. We call an edit cost function reflexive if for all
states x ? x there exists An edit ? ? ?, such that ?(x) = x and C(?, x) = 0.
We call an edit cost function symmetric if C(?, x) = C(??1, ?(x)) for all states
x ? X and all edits ? ? ? where ??1 is the inverse edit for ? on x.
Let GX,? be the legal move graph according to X and ? and let C be
an edit cost function on ?. The edit distance d?,C according to ? and C
is defined as the shortest path distance in the legal move graph GX,? with
the edge weights ?(x, y) = min???{C(?, x)|?(x) = y}. So the formula for the
Preprint as provided by the authors. 10
edit distance is:
d?,C(x, y) := min
?1,...,?T??
x2,...,xT?X
{
T?
t=1
C(?t, xt)
?????x1 = x, ?t(xt) = xt+1, ?T (xT ) = y
}
(1)
If no path between x and y exists, we define d?,C(x, y) =?.
For some combinations of edit sets and edit cost functions, edit distances
can be computed efficiently, even without representing the legal move graph
explicitly. As an example, consider the string edit distance [24] which op-
erates on sequences over some alphabet A. It permits deletions of single
elements in the string, insertions of single elements and replacements of ele-
ments at each position. More precisely, the edit set is defined as
? = {deln, insn,u, repn,u|n ? N, u ? A} where (2)
deln(v1, . . . , vN) = v1, . . . , vn?1, vn+1, . . . , vN (3)
insn,u(v1, . . . , vN) = v1, . . . , vn, u, vn+1, . . . , vN (4)
repn,u(v1, . . . , vN) = v1, . . . , vn?1, u, vn+1, . . . , vN (5)
and the edit cost function is defined as C(deln, x) = C(insn,u, x) = 1 and
C(repn,u, v1, . . . , vN) = 1 if u 6= vn and 0 if u = vn for all n ? N, x ? X, u ? A.
In this case, the overall edit distance can be computed in O(N2) using a
dynamic programming algorithm [24]. Note that ? is reflexive and symmetric
and C is non-negative, reflexive and symmetric. A small excerpt of the legal
move graph of the string edit distance over the alphabet {a, b, c} is shown in
Figure 4 (left). Here, the string “ab” is connected to “bb” because there exists
an edit ? ? ? which transforms “ab” to “bb”, namely rep1,b. The reverse edit
??1 ? ? in this case is rep1,a. Similarly, “ab” is connected to “abc” because
ins3,c(ab) = abc and, inversely, del3(abc) = ab.
Oftentimes in intelligent tutoring systems, states have the form of trees,
for example abstract syntax trees of computer programs [44]. For such data,
the tree edit distance algorithm of Zhang and Shasha is a natural fit and
has been applied in several contributions [7, 11, 30, 44]. Similarly to the
string edit distance, the tree edit distance permits deletion, insertion and
replacements of tree nodes, but the algorithm is more complex with O(N4)
runtime [49]. An alternative has been suggested by Zimmerman et al. who
compute an edit distance on pq-grams in trees, meaning small subtrees, which
results in a considerably faster runtime of O(N · log(N)) [50]. Mokbel et al.
Preprint as provided by the authors. 11
as well as Price et al. have suggested a two-level approach where student
states are first decomposed into fragments which may be arbitrarily ordered
and fragments are compared using a string edit distance [27, 40]. A very
generic approach has been developed by Paaßen et al., who devised a general-
purpose O(N2) algorithm for string edit distances which supports a broad
class of edit sets as well as edit cost functions and relies on the framework
of algebraic dynamic programming [13, 32]. This approach has also been
applied to abstract syntax trees by flattening the trees to sequences of code
statements in order of their execution [32].
Note that an edit distance is not alway guaranteed to correspond to the
semantic distance between states. Consider the UML example in Figure 1
(left). The diagram could be changed, without affecting the computed func-
tion, by renaming the variable m to x, by replacing node 4 with “initialize
z = ?1”, by replacing node 7 with z = 4 + 3 ? 7, or by introducing a node
“initialize y = 4” at some point in the graph. In principle, we can apply
arbitrarily many edits to the graph in Figure 1 (left), without changing the
computed function of the diagram at all. However, if we replace node 10 with
“Return m”, a rather subtle change, the computed function changes consid-
erably. This can negatively impact the capability of a tutoring system to
provide useful hints. Consider the hint policy of Zimmerman and Rupakheti
mentioned above [50]. Due to an edit distance which over-emphasizes seman-
tically irrelevant edits and underestimates the impact of subtle, but semanti-
cally important edits, a hint may be returned which is semantically irrelevant
and does not help the student, while a more important edit, from a semantic
perspective, may be ignored.
One approach to address this issue is canonicalization, which essentially
transforms the raw states in X to a canonic form, such that semantically
equivalent states have the same canonic form. The edit distance is then de-
fined in the canonic forms, leading to a smaller legal move graph and edits
which put stronger emphasis on semantically relevant changes. Canonical-
ization is particularly common in the domain of computer programs, where
the order of binary relations (such as <) or variable names can be normalized
or unreachable code can be removed [43]. Note that it may be ill-advised to
compress the state set too drastically because it may render it impossible to
distinguish between states that require different feedback. For example, tu-
toring systems for computer program often not only intend to teach function-
ally correct programming, but also programming style, such that important
stylistic differences, even though functionally irrelevant, need to be preserved
Preprint as provided by the authors. 12
in the canonic form [35, 7]. Another challenge in canonicalization is that ed-
its on the canonic form may not be interpretable to the user directly, such
that these edits first need to be aligned with the student’s code, a process
that has been dubbed state reification [44].
An alternative approach is metric adaptation. Instead of mapping two
semantically equivalent states x and y to the same canonic form, we could
also lower the cost of edits which transform x to y [32]. This makes it possible
to smoothly regulate the emphasis on semantics, style and syntax and keeps
the original legal move graph intact, such that state reification is unnecessary.
However, metric adaptation is limited by the neighborhood structure in the
original legal move graph and thus can not easily map equivalent states which
are far apart in the legal move graph to the same point. Overall, the most
promising route may be to use (mild) canonicalization and metric adaptation
in conjunction to achieve best results.
In summary, the concepts of edit set, legal move graph and edit distance
permit us to define a hint policy that is mathematically optimal in the sense
that each student will receive a hint which lies on the shortest path to a so-
lution [50]. In order to provide such hints helpful we require an edit distance
which roughly corresponds to the semantic distance between two states, but
also takes important stylistic features into account. Yet, there are still possi-
ble scenarios where such a hint policy may produce low-quality hints from a
pedagogic point of view, namely if the shortest path in the legal move graphs
involves intermediate states which are counter-intuitive to students, that is,
if the shortest path is one that no student would take. To find a path which
takes student’s preferences into account, we can utilize past student’s data,
which brings us to the notion of traces and interaction networks.
2.2 Traces and Interaction Networks
In many cases, legal move graphs are infinite and contain many states which
are absurd and highly unlikely to be visited by students. Interaction networks
aim at capturing the subgraph which is likely to be relevant for feedback and
dismiss the rest of the legal move graph. The relevant subgraph is approxi-
mated by analyzing a dataset of actual student activity on the learning task
and keeping only the states and edits which have actually occurred. In other
words, an interaction networks tries to approximate what students are likely
to do by capturing what past students have done [9, 4].
The student data necessary to generate an interaction network has the
Preprint as provided by the authors. 13
form of traces. Inspired by Eagle et al., we define traces as follows [9]:
Definition 5 (Trace). Let X be a set of possible states for a learning task
and ? be an edit set on X. Then, a sequence x1, ?1, . . . , ?T?1, xT where
xt ? X, ?t ? ? and xt+1 = ?t(xt) is called a trace.
Note that this definition is not exactly equivalent to the one given by Ea-
gle et al. In particular, they do not require actions to be deterministic, that
is, in their framework the same action applied to the same state may lead
to different subsequent states. We could generalize the notion of edits ac-
cordingly, re-defining them as probability distributions on subsequent states,
but as almost all approaches in the literature frame edits as deterministic,
we also employ a more simplistic, deterministic model here.
The interaction network corresponding to a dataset of traces is defined
as follows:
Definition 6 (Interaction Network). Let X be a set of possible states for a
learning task and ? be an edit set onX. Further, let {(xi1, ?i1, . . . , ?iTi?1, x
i
Ti
)}i=1,...,N
be a set of traces. The interaction network corresponding to this set of traces
is defined as the graph G = (V,E) where
V =
{
xit
???i ? {1, . . . , N}, t ? {1, . . . , Ti}} (6)
E =
{
(xit, x
i
t+1)
???i ? {1, . . . , N}, t ? {1, . . . , Ti ? 1}} (7)
Ideally, ? exactly corresponds to the edit set of the legal move graph,
but there are many cases where this condition may not hold. For example,
the edit sets might be different because students work on a different rep-
resentation compared to the representation used to compute edit distances,
for example due to canonicalization [43, 44]. Another reason may be that
student’s states may be recorded only at certain points in time (e.g. when
they explicitly hit a “save” button) such that multiple actions may have been
performed since the last recorded state. Finally, the concrete actions of a
student may not even be available because the students work on the task off-
line and submit their current state only if they need help from the system.
In these cases we have to assume that students may “jump” in the legal move
graph from state to state and the exact path they have taken needs to be
inferred by the system [36].
Consider the example shown in Figure 2. On the left, we show three traces
through a legal move graph. Note that students may leave out intermediate
Preprint as provided by the authors. 14
x1
x11x
2
1
x31
x2 x12
x22
x3 x4
x32
x5
x23
x34
x6x13
x33
?11
?12
?21
?22
?31
?32
?33
x1
x2
x4
x5 x6
Figure 2: An example of an interaction network based on student traces.
Left: The legal move graph from Figure 1 with three student traces (red,
orange and blue). Right: The resulting interaction network corresponding
the traces on the left.
Preprint as provided by the authors. 15
steps in the legal move graph and “jump” directly toward a distant state. On
the right we show the interaction network corresponding to the three traces
on the right. Note that there are much fewer, and different, edges compared
to the legal move graph. In particular, we now have a directed graph instead
of an undirected one and the state x3 is not even part of the interaction
network anymore.
We now have accumulated the necessary basic concepts to introduce the
existing hint policies discussed in the literature, which is our next step.
2.3 Hint policies
Recall the definition of a hint policy (Definition 2). We are referring to a
function which outputs an edit for each possible input state. In the remainder
of this section, we are going to provide a short review of the hint policies that
have been suggested in the literature.
The arguably simplest policy is the one of Zimmerman et al. we intro-
duced above, which always recommends the first edit on the shortest path
to the closest solution [50]. Such an approach does not even require student
data, except for at least one example of a solution. Rivers and Koedinger
take a more advanced approach in their Intelligent Teaching Assistant for
Programming (ITAP), an intelligent tutoring system for Python program-
ming [44]. Their technique involves the following steps: First, they retrieve
the closest solution according to the tree edit distance on canonic forms.
Second, they use the edits which transform from the student state to the
closest correct one to construct a path of intermediate states. Third, of these
intermediate states, the one with the highest desirability score is selected for
feedback, where the desirability score is a weighted sum of the frequency in
past student data, the distance to the student’s state, the number of success-
ful test cases the state passes and the distance to the solution [44]. Finally, an
inverse canonicalization (state reification) step is applied to infer edits that
can be directly applied to the student’s state to transform it to the selected
state.
Both of these approaches have been part of a study by Piech et al. who
compared several hint policies against expert recommendations on a large-
scale dataset consisting of over a million states from theHour of Code Massive
Open Online Course (MOOC). The data was collected from two beginner’s
programming tasks in a block-based programming language. They found that
the policy which agreed most with the recommendations of tutors was a so-
Preprint as provided by the authors. 16
called Poisson path policy, which recommends the first state on the shortest-
path algorithm on a version of the legal move graph which weighted the edges
according to the inverse frequency of the target state in the dataset, that is,
?(x, x?) := N/N(x?) where N is the overall number of states submitted by
successful students and N(x?) is the number of times x? was submitted by
successful students [36].
Instead of recommending edits toward the closest solution, one can rec-
ommend edits toward the closest intermediate state on a trace leading to a
solution. This is the approach of Gross and Pinkwart for supporting stu-
dents learning Java programming in the JavaFIT system1. They distinguish
between two types of help-seeking behavior, namely searching for errors or
searching for a next-step. In both cases, they retrieve the closest state to the
student’s state in the interaction network. If students are trying to find an er-
ror in their code, the system recommends an edit leading the student toward
this reference state, thereby attempting to correct the error. If students as-
sume that their current state is correct, but they are looking for a next step,
the system recommends an edit toward the successor of the reference state,
thereby guiding the student closer to a solution [16]. This policy can be seen
as an instance of case-based reasoning, where recommendations are based on
a similar case from an underlying case base. Freeman et al. have taken this
view to analyze Python programs and used a weighted tree edit distance to
retrieve similar cases [11]. Also similar to case-based reasoning, Gross et al.
proposed example-based feedback, in which the closest prototypical state in
a dataset is retrieved and shown to the student to elicit self-reflection and
sense-making in order to improve their own state [15].
The scheme of Lazar and Bratko takes a different approach by applying
edits that have been frequent in past student traces to manipulate the current
student’s state until an edit is found that achieves better unit test scores [21].
A final approach is the hint factory approach by Barnes et al. [5] They
achieve an optimal hint policy in a precise probabilistic sense by modelling the
multi-step learning task as a Markov Decision Process [46]. Their hint policy
always returns the action which maximizes the expected future reward, where
a reward is given whenever a student has achieved a solution. The model
relies on an estimate of the transition probability distribution P (x?|x, ?) of
moving to state x? if one has been in x and applied action ?. The hint factory
estimates this probability distribution based on transition frequencies in the
1https://javafit.de/
Preprint as provided by the authors. 17
trace data and therefore requires past student data to provide an accurate
estimate.
The hint factory was originally created as a hint-generation add-on to
the DeepThought instruction system for deductive logic [5]. Several studies
have demonstrated that the hint factory reduces student dropout and helps
students to complete more problems more efficiently [45, 8]. The hint factory
has also been applied to further domains, such as the serious game BOTS
[19] or the SNAP programming environment [39].
A schematic overview of the different approaches is shown in Figure 3.
The legal move graph for our example learning task is drawn in gray and
semantically equivalent states which are canonicalized have the same gray
background. We assume that the bottom left state is the initial state and
that the top right state is the solution. Further, we assume that the edit
set of our legal move graph corresponds to the student actions directly. As
training data for the hint policies, the traces of three successful students
(drawn in blue) are available. The trace of the new students who asks for
help is shown in red. She does two edits on her own and then requests a
hint from the system in the highlighted, red state. So which edit would be
recommended by the different hint policies discussed above? The approach
of Zimmerman and Rupakheti (Figure 3a) would just search the shortest
path through the legal move graph to the solution and recommend the first
edit on that path [50]. In our example, this could either be the arrow to the
right or to the top right. The approach of Gross and Pinkwart (Figure 3b)
would select the closest state in a previously seen trace and recommend an
edit toward the successor in that trace, which would be the edit to the right
[16]. Similarly, the hint factory (Figure 3b) would just have information for
one trace in that state and thus would also recommend following this trace
[5]. The Poisson hint policy of Piech et al. (Figure 3c) would search for
the shortest path taking into account state frequency in the available trace
data [36]. Therefore, the edit to the upper left would be recommended, even
though it leads to a longer path and, in this case, takes the student back to a
previous semantic equivalence class. Both the approach of Lazar and Bratko
and the approach of Rivers and Koedinger take semantic equivalence into
account by employing pre-defined tests. Only edits are recommended which
extend the functionality of the previous state by achieving a higher test score
[21, 44]. Further, Rivers and Koedinger explicitly apply canonicalization to
reduce the size of the legal move graph, which would likely collapse some
of the semantically equivalent states to a single point. Finally, Rivers and
Preprint as provided by the authors. 18
(a) [50] (b) [16, 5]
(c) [36] (d) [21, 44]
Figure 3: A schematic comparison of the different hint policies discussed in
this paper. The underlying legal move graph for a learning task is shown in
gray. Gray regions in the background indicate semantically equivalent states
which are mapped to the same canonic form. Three student traces (blue)
serve as training data for the hint policy. States which are not visited by
any student trace are half transparent. The trace of the current student
attempting the task is shown in red. This student proceeds to the high-
lighted red state and then asks the system for help. Each subfigure shows
the recommended hint of a hint policy discussed in this paper in orange.
Preprint as provided by the authors. 19
Koedinger also take into account state frequency to make a recommendation.
In our example, it is likely that they would recommend a more distant state
which ensures a change in terms of semantics, such as the one shown in the
figure (Figure 3d).
Our own approach can be seen as an extension of each of these approaches.
We extend the work of Zimmerman and Rupakheti, Gross and Pinkwart, as
well as Rivers and Koedinger in that we do not only utilize data from one
single reference state but from several ones, which we merge in a probabilistic
model. We extend the work of Lazar and Bratko in that our approach does
not require unit tests to select a viable edit but follows the trajectory of past
students. Our most important inspiration is the hint factory by Barnes et al.,
because we also attempt to build a probabilistic model that describes student
behavior in solving a multi-step task to guide future student’s behavior. We
extend the hint factory, as well as the approach of Piech et al., because
our approach does not require student states to be part of the interaction
network. This key point warrants some further discussion.
The hint factory - as well as the approach of Piech et al. - can provide
hints only for states that are part of the interaction network and for which a
directed path to a solution in the interaction network exists. This has been
dubbed the hintable subgraph [4]. In practice, students may very well find
themselves in states which are not part of the hintable subgraph. Indeed,
research has shown that for a reasonably small, open-ended programming
task, over 90% of states are visited only once, indicating that future students
will likely visit states that have not been seen before and may not even be
connected to previously seen states in the legal move graph [37]; and the num-
ber of unique states remained high even after applying harsh canonicalization
[37]. This also matches our own two datasets, where 97.23% and 82.79% of
states were visited only once. So how can the hint factory be extended to
situations be addressed were student data is sparse? A first approach has
been proposed by Price et al., who suggested contextual tree decomposition
(CTD) which generates interaction networks only for small modules in the
student’s state [38]. Due to the limited size of the modules the variability in
student data is significantly reduced and is easier to cover with interaction
networks corresponding to few traces. A challenge of this approach is that
the system generates hints for each module, from which the student must
select [40]. Our approach addresses this selection problem. However, we also
take a different route to arrive at edits. We do not decompose the student
states into smaller parts, but instead embed students’ states into a continuous
Preprint as provided by the authors. 20
space where a hint policy is easier to obtain. This embedding sets apart our
approach from all other policies described here. The embedding is inspired
by recent work of Paaßen et al. who proposed a prediction scheme for data
that is given in terms of pairwise dissimilarities [33]. We extend this scheme
by also providing a method to infer a recommended edit in the original space
that corresponds to the recommended edit in the continuous space.
We note that there exists at least one embedding approach in the liter-
ature on intelligent tutoring systems, namely the approach of Piech et al.
who proposed an embedding of computer programs via neural networks [35].
The embedding is computed by executing the programs on example data
and recording the variable states P before executing a block of code A as
well as the variable states Q after A has been executed. Both P and Q are
embedded in a common space via a single-layer neural network, yielding the
representations fP and fQ. Then, a matrix MA is constructed which maps
fP to fQ, that is, MA is constructed such that fQ ? MA · fP . This matrix
MA is the embedding of the code block A [35]. We extend this work in two
ways: First, our approach does not need to explicitly compute a embed-
ding but instead relies on an implicit embedding that is based on an edit
distance. Therefore, we also do not not require execution data. Second, be-
cause our proposed embedding relies on the edit distance, it explicitly takes
the compositional structure of the data into account. Finally, we provide
a technique to interpret the predictive result in the continuous space as an
actual, human-readable edit, which the Piech-approach lacks.
In summary, our proposed approach improves upon existing ones on at
least one of two dimensions: First, it has fewer pre-conditions compared to
many other approaches because it requires neither expert hints, nor unit
tests, nor dense coverage of the legal move graph by past student data. It
only requires an edit distance and some (but few) student traces. Second,
it achieves a richer model compared to many other approaches, namely a
probabilistic model of student behavior. In the next chapter, we introduce
our proposed model in detail.
3 Continuous Hint Factory
We define two goals for any hint generated by our hint policy. First, the hint
should seem reasonable to the student requesting it; otherwise, the hint will
likely be ignored [41]. We hypothesize that an action taken by other, students
Preprint as provided by the authors. 21
in the same situation should seem reasonable to the student requesting a hint.
Therefore, creating a reasonable hint entails predicting the most likely edit
that students will make in a given situation. Second, the hint should lead
the student closer to a solution. To align these two goals, we recommend
the most likely edit that has been taken by students who did end up in
the solution. In addition to these two goals, we want the hint policy to
be generalizable to other learning tasks and domains. Therefore, our policy
requires no information about the states themselves, only a way to calculate
the distance between them.
A policy that would achieve our goals in densely populated state spaces
is the hint factory [5]. Relying on the theoretical framework of reinforcement
learning, the hint factory recommends the edit that is most likely to lead
to a solution, given what other students have done in the same situation
[5]. However, in sparsely populated state spaces, data of students in the
same situation is likely not available. Therefore, we need to utilize data of
students in similar situations. More precisely, we embed student data in a
continuous space in which machine learning can help us to address questions
of generalization and model performance in a precise, quantitative fashion.
This scheme inspires the name of our method, the continuous hint factory.
Our approach has three steps. First, we embed student data in a contin-
uous space by means of an edit distance. Second, we develop a hint policy
in this embedding space based on Gaussian process prediction for structured
data [33]. This policy returns the most likely edit for a student in a given
situation based on what successful students have done in similar situations
However, the prediction has the form of a vector in the continuous space.
Therefore, in a third step, we need to transform this vector into a human-
readable edit which can be used as a next-step hint. In the following sections,
we discuss each of these three steps in turn.
3.1 The Edit Distance Space
For our hint policy we require a continuous space in which past and present
student data is embedded. In mathematical terms, this space should be an
Euclidean vector space. A simple example of such an embedding is shown
in Figure 4b. In this figure, the strings “ab”, “aa”, “aac”, “bb”, and “bbc”
are embedded in a two-dimensional space, namely the two dimensions of the
paper. In this embedding, the Euclidean distance between the strings on the
paper approximately corresponds to their edit distance, that is, strings with
Preprint as provided by the authors. 22
abx
aa
x1
aac
y1
bb
x2
bbc
y2
abc
(a) A small excerpt of
the legal move graph
of the string edit dis-
tance over the alpha-
bet {a, b, c}. x = ab
is the current student
state (red). Further, two
traces are given with the
states x1 = aa, y1 = aac,
and x2 = bb, y2 = bbc
respectively (blue).
?(x)
?(x1) ?(y1)
?(x2) ?(y2)
?GPR(x)
(b) The embedding of
the states on the left
into the edit distance
space via the embedding
?. The recommendation
of the Gaussian Process
Regression (GPR) policy
?GPR(x) for the current
student state x is shown
in orange.
abx
aa
x1
aac
y1
bb
x2
bbc
y2
abc
?
(c) The legal move graph
from the left figure, in-
cluding the edit ? (or-
ange) which corresponds
to the recommended edit
of GPR from the center
figure.
Figure 4: An illustration of the continuous hint factory on a simple dataset
of strings. First, we compute pairwise edit distances between the student’s
current state (red) and trace data (blue). These edit distances correspond
to the shortest paths in the legal move graph (left). The edit distances
correspond to a continuous embedding, which we call the edit distance space
(center). In this space, we can infer an optimal edit (orange) using machine
learning techniques, such as Gaussian process regression (GPR). Finally, we
infer the corresponding hint in the original legal move graph (right), which
can then be displayed to the student.
Preprint as provided by the authors. 23
an edit distance of 2, such as “ab” and “aac”, are about twice as far away
from each other on the paper compared to strings with an edit distance of
1, such as “ab” and “aa”. Also note that this embedding is not exact. For
example, the distance on the paper between “ab” and “abc” is much larger
compared to the distance between “ab” and “bb”, even though in both cases
the edit distance is 1. So finding an embedding which permits an exact
correspondence between Euclidean distance and edit distance is not trivial.
Interestingly, though, we can guarantee that such an embedding exists if the
edit distance fulfills some constraints:
Theorem 1 (Latent Distance Space). Let X be some finite set and d :
X × X ? R be a function such that for all x, y ? X it holds: d(x, x) = 0,
d(x, y) ? 0 and d(x, y) = d(y, x). Then, there exists a vector space Y ? Rs
for some s ? N and a mapping ? : X ? Y, such that for all x, y ? X:
d(x, y)2 = (?(x)? ?(y))T · ? · (?(x)? ?(y)) (8)
where ? is a diagonal matrix with entries in {?1, 0, 1}.
Proof. Refer to [17, 34].
Note that if ? has no negative entries, d corresponds to the Euclidean
distance in the embedding space. Otherwise, there exist points in the la-
tent vector space Y for which the pairwise distance becomes negative, which
may cause errors in subsequent processing. These negative entries can be
avoided by eigenvalue correction techniques. Such techniques convert the
matrix of pairwise distances to a matrix of pairwise similarities, decompose
this matrix into its Eigenvectors and Eigenvalues, then sets the Eigenvalues
to non-negative values and convert the resulting similarity matrix back to a
matrix of pairwise distances [14]. Note that this correction is an approxima-
tion and does distort the distances, but only to the extent to which negative
Eigenvalues are present.
Also note that the dimensions of Y have no inherent meaning. The
dimensions are only relevant in that we can fulfill a higher number of distance
constraints in a higher-dimensional space. For an intuition, consider the
example shown in Figure 4b. To construct our embedding, we start with
the strings “ab”, “aa”, and “bb”. The edit distance between “ab” and “aa” as
well as “bb” is 1, while the edit distance between “aa” and “bb” is 2. We
can embed the strings by arbitrarily fixing the location of “ab” to 0 and then
Preprint as provided by the authors. 24
setting the location of “aa” and “ab”, such that the distance constraints are
fulfilled. A one-dimensional solution for this problem is to assign the location
?1 to “aa” and 1 to “bb”. However, we could equally well rotate our solution,
for example by 180?, or shift all positions by any real number to achieve
an equally valid embedding. So neither rotation or absolute location in our
embedded space are interpretable, just the pairwise Euclidean distances are
meaningful. Further, if we also wish to embed the strings “aac” and “bbc”,
we notice that one dimension is not sufficient anymore. Many of the distance
constraints can be fulfilled by assigning the position ?2 to “aac” and 2 to
“bbc”, but then the Euclidean distance between “aac” and “bbc” is 4, while the
edit distance is only 2. Therefore, we must increase the number of dimensions
to fulfill our additional constraints. Indeed, even in two dimensions we can
only approximately fulfil the constraints, as is visible in Figure 4b. Yet, our
theorem shows that there is always some number of dimensions, for which
an exact embedding is possible, and with the help of Eigenvalue correction
we can make this embedding Euclidean. Based on this embedding, we can
prove the main theorem of our work, namely the existence of an edit distance
space:
Theorem 2 (Edit Distance Space). Let X be some finite set of past and
present student data, let ? be a reflexive and symmetric edit set on X and
let C : ? × X ? R be a non-negative, reflexive and symmetric edit cost
function on ?. Further, let D be the eigenvalue-corrected version (via clip)
of the matrix with entries Dij = d?,C(xi, xj) for all xi, xj ? X.
Then there exists a vector space Y = Rs, for some s ? N which we call
the edit distance space for d?,C; and there exists a mapping ? : X ? Y, such
that for all x, y ? X it holds: ??(x) ? ?(y)?22 = D(x, y), i.e. the Euclidean
distance in Y corresponds to d, up to Eigenvalue correction.
Proof. We first show that, under our constraints on ? and C, the resulting
edit distance d?,C fulfills the constraints of theorem 1.
d?,C(x, y) ? 0: If x and y are connected in the legal move graph, d?,C(x, y)
is a sum of non-negative contributions (because C is non-negative), and
thus d?,C(x, y) ? 0. Otherwise d?,C(x, y) =? > 0.
d?,C(x, x) = 0: Because ? and C are reflexive we know that for all states
x ? X there is an edit ? ? ?, such that ?(x) = x and C(?, x) = 0.
Therefore it holds: d?,C(x, x) ? C(?, x) = 0. Because we have already
Preprint as provided by the authors. 25
shown that the edit distance is non-negative, we know that d?,C(x, x) =
0
d?,C(x, y) = d?,C(y, x): Let x, y ? X such that x and y are connected in the
legal move graph. Let ?1, . . . , ?T be a sequence of edits that transforms
x to y such that the cost is minimal. Because ? is symmetric we can
construct the sequence of edits ??1T , . . . , ?
?1
1 which transforms y to x.
Because C is symmetric we know that the cost of this path is equal to
the cost of ?1, . . . , ?T , which in turn implies d?,C(x, y) ? d?,C(y, x). We
can do the same argument in the other direction (from y to x), such
that d?,C(x, y) ? d?,C(y, x), which implies d?,C(x, y) = d?,C(y, x). If
there is no path from x to y in the legal move graph, then there is also
no path from y to x and it holds d?,C(x, y) =? = d?,C(y, x).
Theorem 1 now yields the required embedding. Because of eigenvalue cor-
rection, this embedding is Euclidean.
In our approach, we will make extensive use of the edit distance space.
In particular, we replace the problem of finding a hint policy for the original
edit set of the edit distance by finding a hint policy in the edit distance space.
3.2 A Hint Policy in the Edit Distance Space
Due to theorem 2 we know that, for a reasonably constrained edit distance
d?,C , there exists an embedding in a vector space Y ? Rs, such that the edit
distance corresponds to the Euclidean distance in Y after Eigenvalue correc-
tion. The main advantage of the edit distance space Y is that constructing a
hint policy for vectors is much easier compared to a hint policy for arbitrarily
complicated states. More precisely, we replace the problem of constructing
a hint policy ? : X ? ? with the problem of constructing a hint policy
? : Y ? ?Y , where ?Y is an edit set in the edit distance space, which we
define as follows.
?Y = {?~?|~? ? Y} where ?~? ? Y : ?~?(~?) = ~?+ ~? and CY(?~?, ~?) = ?~??
(9)
In other words: There is an edit ?~? for every vector ~? in the edit distance
space Y and the edit ?~? just adds ~? to its input, that is, for all vectors ~? in
the edit distance space Y we define: ?~?(~?) = ~? + ~?. The cost C of ?~? is just
Preprint as provided by the authors. 26
x1 x2 x3
x4
x5
x6
x7
Figure 5: An illustration of the cycle detection mechanism in the continuous
hint factory. A student works on her state and proceeds steadily for the first
two steps. Then, she embarks on a path which she later undoes again. We
detect this because x7 is as close to x3 as x4. Because of this behavior, we
can remove the states x4, x5 and x6 from the trace and connect x3 directly
with x7.
the length of ~?, that is, for all vectors ~? and ~? in the edit distance space Y ,
we define: CY(?~?, ~?) = ?~??. It is easy to show that the corresponding edit
distance d?Y ,CY is the Euclidean distance in Y : Recall that the edit distance
is defined as the length of the shortest path in the legal move graph if the
edges are weighted according to the edit cost function (refer to equation 1).
For any two points ~x and ~y in Y there exists the edit ?~y?~x ? ?Y . The cost
of that edit is precisely ?~y ? ~x? which is the Euclidean distance between y
and x. Because of the triangular inequality we can guarantee that there is
no sequence of edits with a lower cost than that, which concludes the proof.
Now, recall that theorem 2 tells us that the original edit distance is also
equal to the Euclidean distance in Y (up to Eigenvalue correction), so we
can conclude that for all x, y ? X the original edit distance d?,C and the
edit distance in the edit distance space d?Y ,CY are equal, up to Eigenvalue
correction. Therefore, we can approximate the problem of inferring a hint
policy for ? with a hint policy for ?Y .
Recall that we wish to construct a policy which recommends the most
likely edit according to what successful students have done in the past. How-
ever, even successful students may have taken detours on their path toward
a solution. To get rid of these detours in our trace data, we introduce the
following distance-based heuristic. Let x1, . . . , xT be the states in a student
trace and let d?,C be our edit distance. Then, for all t ? {1, . . . , T ? 1} we
look for t? ? {t + 2, T} such that d(xt, xt?) ? d(xt, xt+1). In such a case, the
student has returned to a previous state (namely to xt) after trying the states
Preprint as provided by the authors. 27
xt+1, . . . , xt??1. Thus, we can shorten the trace to x1, . . . , xt, xt? , . . . , xT (see
Figure 5).
After this pre-processing step, we can start our edit prediction mechanism.
We denote a state in our trace dataset as xi and the next step after it with
yi. If xdataidx is the end point of a trace, then yi = xi. Now, we intend
to construct a hint policy in the edit distance space which can predict the
vector ~?i := ?(yi) ? ?(xi) for all points ?(xi). In machine learning terms,
this is a regression problem. The simplest approach to this problem would
be 1-nearest neighbor regression, which looks for the closest data point in
the database and returns the edit that has been done for that point, that is,
?1NN(?(x)) = ~?i where d(x, xi) is minimal. This is equivalent to the policy of
Gross and Pinkwart [16], which we will use as baseline. Unfortunately, such
a policy necessarily has difficulty to optimally exploit the knowledge encoded
in past student data, because it can only use the edit of one student at a
time. To integrate the edits of multiple students in a probabilistically optimal
fashion, we turn to Gaussian Process Regression (GPR) for structured data
[33]. To apply this technique, we need just one more ingredient, which is a
kernel function. For an exact definition of kernel functions for GPR we point
to the work of Rasmussen and Williams [42]. For our purposes here it suffices
to describe a kernel function as a measure of similarity. In particular, we
use the radial basis function (RBF) kernel, which is defined as: k?,d(x, y) =
exp(?0.5 · d(x,y)
2
?2
) [42]. The RBF kernel measures similarity by assigning a
value of 1 for a distance of 0 and assigns lower values for higher distance,
quickly approaching 0. ? is a hyper-parameter called length-scale which
controls the distance value at which k?,d reaches its maximum slope (see
Figure 6).
Let now ~k(x) be the row vector of kernel values k(x, xi) for all i = 1, . . . ,M
and letK be the matrix of pairwise kernel values k(xi, xi?) for all i = 1, . . . ,M
and i? = 1, . . . ,M . Further, let X be the matrix of all embedded states ?(xi)
as rows and let Y be the matrix of all embedded states ?(yi) as rows. Note
that we will not compute these embeddings explicitly. We will show later that
our approach works without these explicit reference to the embedded states.
Then, for the point ?(x), GPR yields a Gaussian probability distribution
for the edit ~? with mean ~µ(x) and covariance matrix ?2(x) · Is, where Is is
the M ×M -dimensional identity matrix (a matrix of zeros with ones on the
diagonal). The mean ~µ(x) and variance ?2(x) can be computed as follows
Preprint as provided by the authors. 28
0 0.5 1 1.5 2 2.5 3
0
0.2
0.4
0.6
0.8
1
d(x, y)
k
?
,d
(x
,y
)
Figure 6: The output of the radial basis function (RBF) kernel (y-axis) for
distances between two states x and y in the range [0, 1] (x-axis) and a length-
scale of ? = 1 (red line).
[33].
~µ(x) = ~k(x) ·
(
K + ??2 · IM
)?1
·
(
Y ?X
)
and (10)
?2(x) = k(x, x)? ~k(x) · (K + ??2 · IM)?1 · ~k(x)
T
(11)
where ?? is a hyper-parameter which quantifies the assumed amount of noise
in our data. Increasing this parameter makes GPR less accurate, but more
robust and numerically stable. Note that the matrix Y ?X contains the
edits that have occured in our trace data; in particular, the ith row of this
matrix contains exactly the vector ~?i = ?(yi)? ?(xi).
Our hint policy now recommends the edit with the highest probability.
For a Gaussian probability distribution, this is always the mean, that is, we
set ?GPR(x) := ~µ(x) for all x ? X. Thanks to GPR, this policy has several
desirable properties which we want to highlight here. First, if x = xi for some
state xi in the trace data, then ~k(x) equals the ith column in the matrix K.
The product ~k(x) ·K?1 is then equal to a vector of zeros which is only one
at position i. So for ?? = 0, the policy will return exactly the vector ~?i.
Further, if x is far away from all states in the trace data, the vector ~k(x)
Preprint as provided by the authors. 29
will be a approximately a zero vector and thus the prediction will be zero
as well. So the policy gracefully degrades and recommends to do nothing if
our example data is uninformative. For all other cases, the GPR hint policy
combines the edits in the trace data in a linear fashion, which becomes clear
if we re-write: ?GPR(x) =
?M
i=1 ?i(x) · ~?i where ~?(x) = ~k(x) · (K + ??2 · IM)?1.
In this view, ?i(x) can be interpreted as the weight or importance of state
i to state x. In other words, if ?i(x) is positive, then you can improve x
by going in the direction of xi; if ?i(x) is 0, then xi is irrelevant; and if
?i(x) is negative, then you can improve x by going away from xi. We can
also represent the recommendations of the nearest-neighbor policy in this
way, by assigning a weight of ?1 to the nearest neighbor xi and a weight
of 1 to the successor yi. This alternative representation also makes obvious
that our recommended edit can be represented in terms of linear coefficients
~?(x) instead of an explicit vector in the edit distance space. In our actual
implementation, we will exclusively use this representation via coefficients
and will avoid computing the embedding ? for any data points.
As an example for our hint policy, consider the string edit distance exam-
ple shown in Figure 4b. Note that the string edit distances are: d?,C(x, x1) =
d?,C(x, x2) = 1 and d?,C(x1, x2) = d?,C(x2, x1) = 2. For the length scale
? = 0.5 and a noise variance ??2 = 0 we obtain the kernel vector ~k(x) =
( 1?
e
, 1?
e
), the kernel matrix K =
(
1 1
e2
1
e2
1
)
and the coefficient vector ~?(x) =
~k(x) ·K?1 ? (1
2
, 1
2
). Thus, the recommended edit (dashed, orange arrow) is
?GPR(x) ? 12 · ~?1 +
1
2
· ~?2, that is, the average of ~?1 = ?(y1)??(x1) (blue arrow
on the top) and ~?2 = ?(y2)? ?(x2) (blue arrow at the bottom).
Via the hint policy ?GPR we can now recommend edits in the edit distance
space which are optimal according to a Gaussian Process model. However,
this edit has the form of a vector in the edit distance space, or equivalently a
coefficient vector ~?(x), neither of which is directly interpretable by a student.
So our last challenge is to derive a viable hint from our prediction in the edit
distance space. More precisely, we wish to obtain an edit in our original edit
set ? which corresponds to the recommended edit in the edit distance space.
3.3 Edit pre-image problems
The problem of finding an original object which maps to a known point in an
embedding space is called a pre-image problem [3], so the problem of finding
Preprint as provided by the authors. 30
the edit which best corresponds to a recommended edit in the edit distance
space can be described as an edit pre-image problem. We want to emphasize
here that such pre-image problems are typically hard to solve [3] and, to our
knowledge, no approach exists to date which addresses the edit pre-image
problem. In this section, we provide an approximation for this problem
First, following Bakir et al., we re-frame our edit pre-image problem as a
minimization problem: Starting from the student’s current state x, we try to
find the edit ? which brings us closest to the recommended state by Gaussian
process regression (GPR) in the edit distance space:
min
???
??
(
?(x)?
)
?
(
?(x) + ?GPR(x)
)
?2 (12)
A naive approach for this problem would be to just try out all possible
edits ? ? ?, compute the embedding ?
(
?(x)?
)
, then compute the distance
??
(
?(x)?
)
?
(
?(x) +?GPR(x)
)
?2 and afterwards take the edit ? for which the
distance is minimal. The first thing we can improve is to avoid computing
the explicit embedding ?
(
?(x)?
)
, by re-writing our minimization problem in
a simpler form:
Theorem 3. Let ~? be the weights applied by GPR, that is ~? = ~k(x) · (K +
??2 · IM)?1. Then, the maximization problem in 12 can be re-written as:
min
???
d?,C(?(x), x)
2 +
M?
i=1
?i · d?,C(?(x), xi)2 (13)
Proof. To keep this rather technical proof brief, we point to theorems 3 and
4 in the paper of Paaßen et al., which show that we are permitted to re-write
the the distance in 12 as:
min
???
??(?(x))? ?(x))?2 +
M?
i=1
?i · ??
(
?(x)
)
? ?
(
xi
)
?2 ? Z (14)
where Z is some constant that does not depend on ? [33]. Due to theorem 2
we know that the Euclidean distance in the edit distance space corresponds
exactly to the edit distance, which concludes the proof.
This result lets us re-interpret our minimization problem: We want to find
an edit which brings us closer to states that have been weighted positively by
GPR and brings us away from states that have been weighted negatively by
Preprint as provided by the authors. 31
GPR. In a revised approach we could try out all edits ? ? ?, compute the edit
distances d?,C(?(x), xi) and d?,C(?(x), x), and then determine the optimal
edit according to 13. Still, there are two challenges left: First, the edit set ?
is typically very large or even infinite. This issue can be addressed by only
considering edits which are part of the cheapest edit sequence ?1, . . . , ?T that
transforms x to a state xi which has a positive weight ?i. Second, computing
the edit distances d?,C(?(x), xi) for all edits is costly. Fortunately, we can
approximate these edit distances such that we can avoid the explicit edit
distance computation.
Theorem 4. Let C be such that for all x ? X and ? ? ? it holds: d?,C(x, ?(x)) =
C(?, x), that is, it is always cheaper to use a single edit instead of multiple
edits. Then problem 13 can be approximated by:
min
???
C(?, x)2 +
M?
i=1
?i ·
(
d(x, xi) + C?i
)2 (15)
where C?i is ?C(?, x) if ? = ?1 for the cheapest hint sequence ?1, . . . , ?T that
transforms x to xi, and C
(
??1, ?(x)
)
otherwise.
Proof. Consider two cases: If ? = ?1 for the cheapest hint sequence ?1, . . . , ?T
that transforms x to xi, then ?2, . . . , ?T transforms ?(x) to xi and has the
cost d?,C(x, xi)? C(?, x) = d?,C(?(x), xi).
Otherwise we can construct a path from ?(x) to xi via the edit sequence
??1, ?1, . . . , ?T where ??1 is the inverse edit for ? in state x. This path
has the cost d?,C(x, xi) + C
(
??1, ?(x)
)
which constutes an upper bound for
d?,C(?(x), xi). Our overall approximation is d?,C(?(x), xi) ? d?,C(x, xi) + C?i
where C?i is ?C(?, x) if ? = ?1 and C
(
??1, ?(x)
)
otherwise.
In our experiment, we use an even tighter approximation for the case of
the string edit distance. Recall that a string edit distance permits deletion,
insertion and replacement operations at each position in the string (also refer
to equation 2 above). If ? is a replacement operation, that is, ? = repn,u for
some position n and some character u, and if ?1 . . . ?T is the cheapest edit
script transforming x to xi which contains an edit of the form ?t = repn,v
for some character v, then we can transform ?(x) to xi by just applying the
edits ?1 . . . ?T , which now replace u with v, which is as most as expensive
as the edit sequence ??1?1 . . . ?T . Similar arguments are possible for other
Preprint as provided by the authors. 32
combinations of edits as well, but we omit the detailed discussion here for
the sake of brevity.
Our pre-image search mechanism is illustrated in Figure 4c. Recall that
the weights of GPR for our states are ?x1 = ?x2 ? ?12 and ?y1 = ?y1 ?
1
2
.
So we need to find an edit which brings us closer to y1 = aac and y2 =
bbc but further away from x1 = aa and x2 = bb. The edits rep2,a and
ins3,c bring us closer to y1 and the edits rep1,b and ins3,c bring us closer
to y2. We now try each of those edits in turn. Applying rep2,a results in
rep2,a(ab) = aa, and we obtain C?x1 = C?y1 = ?C(rep2,a, ab) = ?1, as well
as C?x2 = C?y2 = C(rep2,b, aa) = 1, which leads us to a value of 12 ? 12(1 ?
1)2 + 1
2
(2? 1)2 ? 1
2
(1 + 1)2 + 1
2
(2 + 1)2 = 4 according to 15. Applying rep1,b
also leads to a value of 4 for symmetry reasons. Applying ins3,c results in
ins3,c(ab) = abc, and we obtain C?x1 = C?x2 = C(del3, abc) = 1, as well as
C?y1 = C?y2 = ?C(ins3,c, ab) = ?1, which leads us to a value of 12 ? 12(1 +
1)2 + 1
2
(2? 1)2 ? 1
2
(1 + 1)2 + 1
2
(2? 1)2 = ?2 according to 15. Therefore, we
would select the edit ins3,c.
Note that we would not have obtained the same result for the one-nearest-
neighbor policy. In this case, all three edits, rep2,a, rep1,b, and ins3,c would
have appeared equally valid because we only utilize the information contained
in one other trace and do not combine information from different traces. This
is the main advantage of our approach above existing approaches: By means
of a continuous embedding and Gaussian process regression for structured
data, we are able to integrate the edits of multiple past students in a prob-
abilistic compromise. As such, our approach combines approaches for dense
state spaces with approaches for vast and sparsely populated solution spaces,
namely a probabilistic model, similar to the hint factory [5], and the nearest-
neighbor principle as used by Rivers and Koedinger [44], Zimmerman and
Rupakheti [50], as well as Gross and Pinkwart [16]. For students, this means
that they will receive hints that reflect the collective understanding of many
capable students instead of that try to follow the nearest student in detail,
including all eccentricities of her approach. This concludes our description of
the continuous hint factory. In the next section, we evaluate the continuous
hint factory on real-world data.
4 Experiments
In our experiments, we investigate two research questions:
Preprint as provided by the authors. 33
RQ1: How well does the Gaussian Process model capture the behavior of
capable students, that is, can the Gaussian process predict what a capable
student would do?
RQ2: Do the hints of the Continuous Hint Factory correspond to the hints
of human tutors?
4.1 Modelling Student Behavior
For RQ1, we considered data which is inherently challenging to predict,
namely data from an open-ended programming task, collected in an intro-
ductory undergraduate computing course for non-computer science majors
during the Fall of 2015 at a research university in the south-eastern United
States. The course had approximately 80 students, split among six lab sec-
tions. The first half of the course focused on learning the Snap2 programming
language through a curriculum based on the Beauty and Joy of Computing
[12]. Here, we focus on the “Guessing Game” task, which had the follow-
ing description: “The computer chooses a random number between 1 and
10 and continuously asks the user to guess the number until they guess cor-
rectly.” Students did not receive specific instructions regarding the form of
the program. A sample state is presented in Figure 7a. Students worked
on this assignment during class for approximately one hour, with a Teaching
Assistant (TA) available to assist them and the option of working in pairs.
The class was conducted as normal, and the students were not informed that
data was being collected. A state of the student’s program was recorded
after every edit. Students who did not correctly select the assignment they
were working on were excluded from the analysis. The dataset consists of 52
traces with 8669 states overall.
Each of the final states was graded by two independent graders. The
graders used a rubric consisting of nine assignment objectives and marked
whether each state successfully or unsuccessfully completed each objective.
The graders had an initial agreement of 94.5%, with Cohen’s ? = 0.544.
After clarifying objective criteria, each grader independently regraded each
state where there was disagreement, reaching an agreement of 98.1%, with
Cohen’s ? = 0.856. Any remaining disagreements were discussed to create
final grades for each assignment. As our aim is to predict what capable
2http://snap.berkeley.edu
Preprint as provided by the authors. 34
(a) (b)
Figure 7: a) A screenshot from the Snap programming environment. b) A
2D visualization of ten example traces in the Snap dataset. All traces start in
the upper right and move toward the left. The 2D embedding was obtained
via non-metric multi-dimensional scaling using the pairwise edit distances as
input, that is, if two states have an edit distance of 0, they are mapped to the
same point in 2D, and if they have a higher edit distance, they are mapped
to points which are further apart. Colors are used to distinguish between
different traces. States within one trace are connected by arrows.
students would do, we kept only traces which successfully completed at least
eight of the nine objectives. This left 47 traces with 7864 states.
As an edit distance, we employed a string edit distance on the sequence
of syntactic building blocks of Snap programs. The building blocks were
annotated by their label (e.g. “doIf”, “var”, “literal”) as well as their relative
depth in the abstract syntax tree(s) (0 for each root node and 1 for the deepest
nodes in the AST). The edit costs were set to 1 for deletion and insertion
operations and to 1
2
· (Clabel + |depth ? depth?|) for replacement operations
where Clabel is 0 if the labels of the node before and after replacement agree
and 1 if they do not, and “depth” and “depth’ ” are the depth of the node
before and after replacement respectively. The edit distance was computed
using the TCS Alignment Toolbox [31]. First, we computed the pairwise edit
Preprint as provided by the authors. 35
distances inside traces and applied the cycle detection mechanism, which
left 2066 states. For these 2066 remaining states, we computed all pairwise
edit distances and applied Eigenvalue correction with the clip method as
suggested by Gisbrecht et al. [14]. Note that of the 2066 remaining states,
1875 were unique according to our edit distance, and of these, 97.23% were
visited only once. The lack of overlap in this dataset is also visible in the
2-dimensional embedding of the dataset in Figure 7b. Due to this lack of
overlap, frequency-based models such as required by the hint factory are
difficult to construct, which motivates the use of our method.
In our experiment we iterated over all 47 traces and, for all states xt within
the current trace, applied the GPR hint policy ?GPR using the remaining 46
traces as training data 3. We selected the length scale ? and the noise
parameter ?? via random search as suggested by Bergstra and Bengio [6]. For
the recommended next state ?(xt) + ?GPR(xt) in the edit distance space we
computed two evaluation measures: first, the squared Euclidean distance in
the edit distance space between the recommended next state ?(xt)+?GPR(xt)
and the actual next state ?(xt+1) of the student. This measure indicates how
well we can predict what a capable student will do based on what other
capable students have done. Second, we computed the squared Euclidean
distance in the edit distance space between the recommended next state
?(xt)+?GPR(xt) and the final state xT of the student. This measure indicates
how close the recommended edit brings us to a solution if the task, that is, it
tells us if following the path of capable students does actually bring us closer
to a solution. Note that this measure is included for overview purposes
and does not address our research question RQ1 directly. We average both
evaluation measures over the trace and take the root, which is then called
the root mean square error (RMSE).
We compare the GPR hint policy with three other hint policies: First,
a simple baseline of always recommending to do nothing; second, the policy
of Gross et al. which recommends the successor of the next student state in
the data base, which is essentially a one-nearest-neighbor hint policy [16];
third, the hint policy of Zimmerman and Rupakheti, which recommends the
closest solution, meaning the closest end point in one of the other 46 traces
[50]. Note that we do use a different distance measure than Zimmerman
and Rupakheti. Their proposed policy may very well work better with the
3Our implementation of the GPR hint policy is available under the DOI 10.4119/u-
nibi/2913104
Preprint as provided by the authors. 36
Table 1: The mean and standard deviation (in brackets) of the RMSE for the
snap dataset. The evaluated hint policies are shown in rows, the different
evaluation measures (distance to the actual next step and distance to the
actual final state of the student) are shown in columns.
hint policy next step error final step error
no action 0.313 (0.022) 0.620 (0.036)
1-NN / [16] 0.406 (0.049) 0.611 (0.041)
[50] 0.580 (0.038) 0.413 (0.061)
Gaussian Process 0.290 (0.031) 0.608 (0.037)
pq-gram tree distance, but in the interest of a fair comparison we applied all
hint policies based on the same distance measure.
Table 1 shows the mean RMSEs and their standard deviation across all
47 traces. We see that our proposed Gaussian process hint policy has lower
RMSE in predicting the next step compared to all other policies. This dif-
ferences are highly significant (p < 10?3 in a signed Wilcoxon rank-sum
test after Bonferroni correction). In bringing students closer to a solu-
tion, the Gaussian process hint policy does better than the baseline and
the one-nearest-neighbor policy of Gross and Pinkwart (p < 10?3 in a signed
Wilcoxon rank-sum test after Bonferroni correction), but is outperformed by
the policy of Zimmerman and Rupakheti. This is not surprising given that
the sole purpose of the latter policy is to find the fastest route toward a
solution, while our own policy also attempts to find a way that follows what
other students have done, which may result in better hint quality as we will
see in the next experiment.
Note that we have not compared GPR with more intricate policies, be-
cause these have requirements which are not fulfilled by our setup: The
hint factory as well as the Poisson path policy by Piech et al. rely on over-
lap between traces to achieve meaningful approximations of their underlying
probability distributions [5, 36]. However, in this dataset, overlap is rare.
Further, we do not have unit tests at our disposal, which prevented us from
applying the policies of Rivers and Koedinger or Lazar and Bratko [21, 44].
We emphasize that we do not make any claim that our method would be
better in settings where these alternative policies are applicable. We just try
Preprint as provided by the authors. 37
to investigate whether we can improve the state-of-the-art in settings where
student data is very sparse in comparison to the size of the state space and
auxiliary information, such as unit tests, are not available.
4.2 Hint Quality
To investigate RQ2, we require an objective measure of hint quality. We chose
to compare the hints provided by the system to hints provided by human
tutors, similar to Price et al. [40]. We utilized data collected in a beginner’s
programming course for computer scientists at a German university in 2012.
The students were faced with the task to draw a UML activity diagram which
described the process of adding two binary numbers (see Figure 8). From
the student states we extracted six typical strategies that occurred in the
states and manually created two correct and one erroneous trace for each
strategy. We presented each state in the erroneous traces to three tutors
who independently were asked to suggest all possible edit hints that could be
given to a student in the particular situation, taking past states into account.
They also were asked to grade their hints with a real value in the interval
[0, 1] indicating hint quality, taking into account the following criteria: 1)
Does the hint follow the strategy of the student? 2) Does the hint conform
to the student’s current focus of attention or does it address a different part of
the state? 3) Is the hint effective in addressing the problems in the student’s
state? 4) Is the hint effective in guiding the student toward a solution? In
a second meeting, all tutors met to add ratings for the hints of the other
tutors and to address discrepancies in the ratings. If after discussion at least
one expert rated a hint with a grade below 0.5, the hint was excluded from
the set. Overall, the dataset consisted of 12 correct traces with a total of
364 states and 6 erroneous traces with a total of 115 states with a total of
1053 hints. The average inter-rater correlation via Pearson’s r was r = 0.588,
indicating moderate agreement. This dataset is available on-line under the
DOI 10.4119/unibi/2913083.
As in the first experiment, we relied on a variation of the string edit
distance which we computed on strings of edges and nodes in the UML
diagrams. We generated the strings by ordering the nodes and edges of
the UML diagrams according to their execution sequence and concatenated
different branches after a fork or decision node in the diagram. We defined the
edit cost as 1 for insertions of deletions, as? for replacements between nodes
of different types (to prevent the string edit distance from replacing nodes
Preprint as provided by the authors. 38
0
Let x be a binary number with m digits (first input)
1
Let y be a binary number with n digits (second input)
2
3
Pad x with zeros in front until it has n digits
4
m <= n
Pad y with zeros in front until it has m digits
6
n < m
m := n
5
7
Initialize z as binary number with m digits
8
Initialize c := 0
9
Initialize i := m
10
11
12
i > 0
return z
21
otherwise
z[i] := 0
13
x[i] + y[i] + c = 0
z[i] := 1
14
x[i] + y[i] + c = 1
z[i] := 0
16
x[i] + y[i] + c = 2
z[i] := 1
18
x[i] + y[i] + c = 3
19
c := 0
15
c := 1
17
i := i - 1
20
22
Figure 8: A correct example solution for the UML binary adder task.
Preprint as provided by the authors. 39
with different types), as 0 for replacements between nodes of the same type,
except for actions. For subsequent actions, we also permitted re-orderings
and defined the edit costs between replacements of actions with different text
as 1 and with the same text as 0. Note that we applied canonicalization in this
dataset: We normalized the order of binary comparisons, as well as the order
of branches after decision nodes, and we made our edit distance invariant
against ordering changes in subsequent actions. Despite this canonicalization,
there were 215 unique states in the training dataset of 364 states and of these,
82.79% were visited only once.
In our experiment, we let the continuous hint factory (CHF) recommend
an edit hint for each erroneous state and compared it with the hints recom-
mended by tutors. If the recommended hint of the CHF matched at least
one tutor hint, we graded the CHF hint with the average rating of the tutors
for this hint, otherwise the rating was set to 0. In comparing system hints
with the hints of tutors, we roughly follow the evaluation scheme suggested
by Price et al. [40]. Again, we compare our system with the policy of Gross
and Pinkwart [16] and the policy of Zimmerman and Rupakheti [50]. For
all these policies we excluded hints that just deleted nodes in the diagram,
because we regard deletions as less informative in that they just provide neg-
ative feedback to the student without a constructive counter-proposal. If a
policy rated multiple hints as optimal, we chose the hint that changed the
most recently added node in the student’s diagram.
As a worst-case baseline we also report hints that were generated by
selecting a random reference state from the data base (“random”) and always
recommending the best human-crafted hint (“tutor”).
The experimental results are shown in table 2. We report the median
rating for the hints, the mean rating, the standard deviation in ratings, the
fraction of ratings with a rating > 0.5, the root mean square error (RMSE)
with respect to the closest tutor hint and the fraction of states for which the
policy returned a hint that was not a deletion. Note that the number of inde-
pendent samples (6) is too low for meaningful statistical tests. Even though
we describe the results in terms of “better” or “worse”, these descriptions do
not imply statistical significant differences.
As one would expect, all other policies appear to perform considerably
better than the random policy. We also note that our proposed Gaussian pro-
cess policy and the policy of Gross and Pinkwart perform better compared
to the policy of Zimmerman and Rupakheti in terms of median and mean
hint quality, fraction of hints with quality > 0.5 and RMSE. However, the
Preprint as provided by the authors. 40
Table 2: The evaluation of hint policies for the UML dataset in terms of hint
quality. Each row displays the valuation results for one hint policy. Each
column displays the result for one evaluation criterion, namely the median
hint quality, the mean hint quality, the standard deviation in hint quality,
the fraction of hints with a quality > 0, the root mean squared distance to
the closest tutor hint, and the fraction of states for which the policy could
provide a hint that was not a deletion (the “hintable” states).
hint quality RMSE hintable
hint policy median mean std. > 0.5
random 0 0.294 0.441 31.3% 0.653 82.6%
tutor 1 0.994 0.021 100% 0 100%
1-NN / [16] 1 0.643 0.466 66.1% 0.248 94.8%
[50] 0.833 0.531 0.48 55.7% 0.585 100%
Gaussian Process 1 0.639 0.457 67% 0.157 92.2%
policy of Zimmerman and Rupakheti was able to provide hints in all cases,
which is neither the case for the policy of Gross and Pinkwart nor for our
proposed one. The reason is that we excluded edits which would just delete
parts of the student’s state without providing a counter-proposal. The dif-
ferences between our proposed policy and the policy by Gross and Pinkwart
are minor, except for the RMSE, which is considerably lower for the Gaus-
sian process policy, indicating that hints of our proposed policy are close to
tutor-crafted hints in the edit distance space, but due to Eigenvalue correc-
tion and approximations in the pre-image finding scheme, this advantage in
quality may get lost. We also note that the hint quality of both policies is
quite high, with a median quality of 1, indicating that the task may be too
easy to reveal meaningful differences.
An interesting finding is that the policy of Zimmerman and Rupakheti
performed relatively poorly, even though it aims at guiding students directly
to a solution. This is likely the case because, if the edit distance between the
solution and the current state of the student is high, many edits are possible
and equally valid to guide a student closer to a solution. In such a case,
the policy likely selects an edit which introduces an advanced step too early,
leading to a low hint quality rating. This is directly related to the fact that
Preprint as provided by the authors. 41
Let x be the first input.
Let m = |x|
Let y be the second input.
Let n = |y|
Pad x with zeros in front until it has n digits.
m < n
Let x be the first input.
Let m = |x|
Let y be the second input.
Let n = |y|
z[i] := 0
¬x[i] ? ¬y[i] ? ¬c
Figure 9: An example for edits (orange) suggested by the continuous hint
factory (left) as well as the policy of Zimmerman and Rupakheti [50, right].
the shortest path toward the solution may be not always be the most intuitive
one. As an example, consider the state displayed in Figure 9. The student has
completed initialization of two input numbers x and y and has also inserted
a decision node. The continuous hint factory correctly recommends to start
padding the first input x if it is shorter than y. The policy of Zimmerman
and Rupakethi, on the other hand, recommends to set a bit in the output
number z, which has not even been initialized yet.
Further, a closer look revealed that all policies achieved perfect hints for
the first two to four steps in each policy, because the beginning for each
diagram was essentially the same. This is important in light of the research
of Price et al. which indicates that students are more likely to seek help and
follow hints if early hints provided by the system were useful [41].
5 Conclusion
This work makes two primary contributions: First, we have provided a math-
ematical framework for edit-based hints and placed prior contributions within
this framework. We also have introduced the concept of the edit distance
space, which is a continuous embedding of student states for which the edit
Preprint as provided by the authors. 42
distance corresponds to the Euclidean distance in the embedding space. Sec-
ond, we introduced the continuous hint factory, a novel hint policy which
provides edit hints to students by combining probabilistic modelling inspired
by the hint factory with the nearest neighbor principle commonly used in
hint policies for vast and sparsely populated state spaces.
In our experiments we have shown that the Gaussian process model is
able to predict what capable students would do. We have also demonstrated
that the hints provided by the continuous hint factory match what human
tutors would have recommended in a given situation, although the hints, on
average, have lower quality compared to the feedback given by human tutors.
With this new hint policy we have extended the capabilities of intelligent
tutoring systems to provide edit hints to student even in tasks where state
spaces are vast and student data is sparse. We have also provided a bet-
ter theoretical overview of edit distances and edit-based hint policies which
hopefully facilitates future research in the field.
We note that the continuous hint factory still has several limitations. In
particular, the hint factory can only be applied if an edit distance is available
which is efficient, takes syntax and semantics into account appropriately and
yields edits that are viable as next-step-hints for the student. This is not an
issue for the domain of computer programming, as edit distances appear as
a natural fit for syntax-tree-based representations of programs, but may be
an issue for other domains. Further, as any data-driven hint approach, hint
quality will suffer if the strategy of a new student is substantially different
from anything that the system has seen before. With regards to evaluation,
our assessment of hint quality is not definitive and it appears likely that our
proposed approach only yields significant advantages compared to existing
work on more complicated tasks compared to the one we investigated. Fur-
ther, we do not yet know how a difference in hint quality translates to learning
outcomes in students. After all, better hints from the view of a tutor may
not always yield better learning outcomes, due to difficulties in sense-making
or lack of prior knowledge on the student’s side [2]. Finally, we acknowledge
that our evaluation is rather narrow, including only two learning tasks from
different domains.
With regards to future work, it appears promising to combine our pro-
posed approach with other work presented in the literature, in particular
canonicalization, state re-ification, unit tests and frequency information as
suggested by Rivers and Koedinger [44], or more sophisticated edit distances
as suggested by Mokbel et al. Paaßen et al. and Price et al. [27, 32, 40]. In-
Preprint as provided by the authors. 43
corporating such approaches has the potential to enhance the edits suggested
by the continuous hint factory significantly and, ideally, reach human-level
quality in recommending edit hints. We also hope the continue to refine
methods for evaluating and comparing hint quality across hint policies, to
allow for better a better understanding of each policy’s strengths and weak-
nesses.
6 Acknowledgement
This research was funded by the German Research Foundation (DFG) as part
of the project “Learning Dynamic Feedback for Intelligent Tutoring Systems”
under the grant number HA 2719/6-2 as well as the Cluster of Excellence
Cognitive Interaction Technology ’CITEC’ (EXC 277), Bielefeld University
and the NSF under grant number #1432156 “Educational Data Mining for
Individualized Instruction in STEM Learning Environments” with Min Chi
& Tiffany Barnes as Co-PIs. We also wish to express our gratitude to our
anonymous reviewers who helped to substantially increase the quality of our
contribution.
References
[1] V. Aleven, B. M. McLaren, J. Sewall, and K. R. Koedinger. A new
paradigm for intelligent tutoring systems: Example-tracing tutors. In-
ternational Journal of Artificial Intelligence in Education, 19(2):105–
154, 2009. URL: http://ijaied.org/pub/1149/.
[2] V. Aleven, I. Roll, B. M. McLaren, and K. R. Koedinger. Help helps,
but only so much: Research on help seeking with intelligent tutoring
systems. International Journal of Artificial Intelligence in Education,
26(1):205–223, 2016. doi:10.1007/s40593-015-0089-1.
[3] G. H. Bak?r, J. Weston, and B. Schölkopf. Learning to Find Pre-images.
In S. Thrun, L. K. Saul, and P. B. Schölkopf, editors, Proceedings of the
16th International Conference on Neural Information Processing Sys-
tems (NIPS 2003), pages 449–456. MIT Press, 2003. URL: https://
papers.nips.cc/paper/2417-learning-to-find-pre-images.html.
Preprint as provided by the authors. 44
[4] T. Barnes, B. Mostafavi, and M. J. Eagle. Data-Driven Domain Models
for Problem Solving, volume 4 of Design Recommendations for Intelli-
gent Tutoring Systems. US Army Research Laboratory, 2016.
[5] T. Barnes and J. Stamper. Toward automatic hint generation for logic
proof tutoring using historical student data. In B. P. Woolf, E. Aïmeur,
R. Nkambou, and S. Lajoie, editors, Proceedings of the 9th International
Conference on Intelligent Tutoring Systems (ITS 2008), pages 373–382,
Montreal, Canada, 2008. doi:10.1007/978-3-540-69132-7_41.
[6] J. Bergstra and Y. Bengio. Random search for hyper-parameter opti-
mization. Journal of Machine Learning Research, 13:281–305, Feb 2012.
URL: http://www.jmlr.org/papers/v13/bergstra12a.html.
[7] R. R. Choudhury, H. Yin, and A. Fox. Scale-driven automatic hint gen-
eration for coding style. In A. Micarelli, J. Stamper, and K. Panourgia,
editors, Proceedings of the 13th International Conference on Intelligent
Tutoring Systems (ITS 2016), pages 122–132, Zagreb, Croatia, 2016.
doi:10.1007/978-3-319-39583-8_12.
[8] M. Eagle and T. Barnes. Evaluation of automatically generated
hint feedback. In S. K. D’Mello, R. A. Calvo, and A. Olney, edi-
tors, Proceedings of the 6th International Conference on Educational
Data Mining (EDM 2013), pages 372–374, Memphis, Tennessee, USA,
2013. URL: http://www.educationaldatamining.org/conferences/
index.php/EDM/2013/paper/download/1099/1065.
[9] M. Eagle, M. Johnson, and T. Barnes. Interaction networks: Gen-
erating high level hints based on network community clustering. In
K. Yacef, O. Zaïane, H. Hershkovitz, M. Yudelson, and J. Stamper, ed-
itors, Proceedings of the 5th International Conference on Educational
Data Mining (EDM 2012), pages 164–167, Chania, Greece, 2012. URL:
http://files.eric.ed.gov/fulltext/ED537223.pdf.
[10] M. L. Fleming and W. H. Levie. Instructional Message Design: Princi-
ples from the Behavioral and Cognitive Sciences. Educational Technol-
ogy Publications, Englewood Cliffs, NJ, USA, 1993.
[11] P. Freeman, I. Watson, and P. Denny. Inferring student coding goals
using abstract syntax trees. In A. Goel, M. B. Díaz-Agudo, and T. Roth-
Berghofer, editors, Proceedings of the 24th International Conference on
Preprint as provided by the authors. 45
Case-Based Reasoning Research and Development (ICCBR 2016), pages
139–153, Atlanta, GA, USA, 2016. doi:10.1007/978-3-319-47096-2_
10.
[12] D. Garcia, B. Harvey, and T. Barnes. The Beauty and Joy of Computing.
ACM Inroads, 6(4):71–79, 2015. doi:10.1145/2835184.
[13] R. Giegerich, C. Meyer, and P. Steffen. A discipline of dynamic program-
ming over sequence data. Science of Computer Programming, 51(3):215
– 263, 2004. doi:10.1016/j.scico.2003.12.005.
[14] A. Gisbrecht and F.-M. Schleif. Metric and non-metric proximity
transformations at linear costs. Neurocomputing, 167:643–657, 2015.
doi:10.1016/j.neucom.2015.04.017.
[15] S. Gross, B. Mokbel, B. Hammer, and N. Pinkwart. Example-based
feedback provision using structured solution spaces. International Jour-
nal on Learning Technologies, 9(3):248–280, 2014. doi:10.1504/IJLT.
2014.065752.
[16] S. Gross and N. Pinkwart. How do learners behave in help-seeking
when given a choice? In C. Conati, N. Heffernan, A. Mitrovic, and
M. F. Verdejo, editors, Proceedings of the 17th International Confer-
ence on Artificial Intelligence in Education (AIED 2015), pages 600–
603, Madrid, Spain, 2015. doi:10.1007/978-3-319-19773-9_71.
[17] B. Hammer and A. Hasenfuss. Topographic mapping of large dissim-
ilarity data sets. Neural Computation, 22(9):2229–2284, 2010. doi:
10.1162/NECO_a_00012.
[18] A. Head, E. Glassman, G. Soares, R. Suzuki, L. Figueredo, L. D’Antoni,
and B. Hartmann. Writing reusable code feedback at scale with mixed-
initiative program synthesis. In Proceedings of the Fourth ACM Con-
ference on Learning@Scale (L@S 2017), pages 89–98, Cambridge, MA,
USA, 2017. ACM. doi:10.1145/3051457.3051467.
[19] A. Hicks, B. Peddycord, and T. Barnes. Building games to learn from
their players: Generating hints in a serious game. In S. Trausan-
Matu, K. E. Boyer, M. Crosby, and K. Panourgia, editors, Proceed-
ings of the 12th International Conference Intelligent Tutoring Systems
Preprint as provided by the authors. 46
(ITS 2014), pages 312–317, Honolulu, HI, USA, 2014. doi:10.1007/
978-3-319-07221-0_39.
[20] K. R. Koedinger, E. Brunskill, R. S. Baker, E. A. McLaughlin, and
J. Stamper. New potentials for data-driven intelligent tutoring system
development and optimization. AI Magazine, 34(3):27–41, 2013. doi:
10.1609/aimag.v34i3.2484.
[21] T. Lazar and I. Bratko. Data-driven program synthesis for hint
generation in programming tutors. In S. Trausan-Matu, K. E.
Boyer, M. Crosby, and K. Panourgia, editors, Proceedings of the
12th International Conference on Intelligent Tutoring Systems (ITS
2014), pages 306–311, Honolulu, HI, USA, 2014. doi:10.1007/
978-3-319-07221-0_38.
[22] N.-T. Le. A classification of adaptive feedback in educational systems
for programming. Systems, 4(2), 2016. doi:10.3390/systems4020022.
[23] N.-t. Le and N. Pinkwart. Towards a classification for programming ex-
ercises. In Proceedings of the 2nd Workshop on AI-supported Education
for Computer Science (AIEDCS), pages 51–60, Honolulu, Hawaii, 2014.
[24] V. I. Levenshtein. Binary codes capable of correcting deletions, inser-
tions, and reversals. Soviet Physics Doklady, 10(8):707–710, 1965.
[25] C. Lynch, K. D. Ashley, N. Pinkwart, and V. Aleven. Concepts,
structures, and goals: Redefining ill-definedness. International Jour-
nal of Artificial Intelligence in Education, 19(3):253–266, 2009. URL:
http://www.ijaied.org/pub/1294/.
[26] V. J. Marin, T. Pereira, S. Sridharan, and C. R. Rivero. Automated per-
sonalized feedback in introductory java programming moocs. In 33rd In-
ternational IEEE Conference on Data Engineering (ICDE 2017), pages
1259–1270, San Diego, CA, USA, April 2017. doi:10.1109/ICDE.2017.
169.
[27] B. Mokbel, S. Gross, B. Paaßen, N. Pinkwart, and B. Ham-
mer. Domain-Independent Proximity Measures in Intelligent Tu-
toring Systems. In S. K. D’Mello, R. A. Calvo, and A. Ol-
ney, editors, Proceedings of the 6th International Conference on Ed-
ucational Data Mining (EDM 2013), Memphis, Tennessee, USA,
Preprint as provided by the authors. 47
2013. URL: http://www.educationaldatamining.org/conferences/
index.php/EDM/2013/paper/download/1063/1029.
[28] T. Murray, S. Blessing, and S. Ainsworth. Authoring tools for advanced
technology learning environments: Toward cost-effective adaptive, inter-
active and intelligent educational software. Springer, Berlin/Heidelberg,
2003.
[29] M. J. Nathan, K. R. Koedinger, and M. W. Alibali. Expert blind spot:
When content knowledge eclipses pedagogical content knowledge. In
Proceedings of the Third International Conference on Cognitive Science,
pages 644–648, Beijing, China, 2001.
[30] A. Nguyen, C. Piech, J. Huang, and L. Guibas. Codewebs: Scal-
able homework search for massive open online programming courses.
In Proceedings of the 23rd International Conference on World Wide
Web (WWW 2014), pages 491–502, Seoul, Korea, 2014. doi:10.1145/
2566486.2568023.
[31] B. Paaßen, B. Mokbel, and B. Hammer. A toolbox for adaptive
sequence dissimilarity measures for intelligent tutoring systems. In
O. C. Santos, J. G. Boticario, C. Romero, M. Pechenizkiy, A. Mer-
ceron, P. Mitros, J. M. Luna, C. Mihaescu, P. Moreno, A. Her-
shkovitz, S. Ventura, and M. Desmarais, editors, Proceedings of
the 8th International Conference on Educational Data Mining (EDM
2015), pages 632–632. International Educational Datamining Soci-
ety, 2015. URL: http://www.educationaldatamining.org/EDM2015/
uploads/papers/paper_257.pdf.
[32] B. Paassen, B. Mokbel, and B. Hammer. Adaptive structure metrics
for automated feedback provision in intelligent tutoring systems. Neu-
rocomputing, 192:3–13, 2016. doi:10.1016/j.neucom.2015.12.108.
[33] B. Paaßen, C. Göpfert, and B. Hammer. Time Series Prediction for
Graphs in Kernel and Dissimilarity Spaces. Neural Processing Letters,
2017. epub ahead of print. doi:10.1007/s11063-017-9684-5.
[34] E. P?kalska. The dissimilarity representation for pattern recognition:
foundations and applications. PhD thesis, 2005.
Preprint as provided by the authors. 48
[35] C. Piech, J. Huang, A. Nguyen, M. Phulsuksombati, M. Sahami, and
L. Guibas. Learning program embeddings to propagate feedback on
student code. In F. Bach and D. Blei, editors, Proceedings of the 32nd
International Conference on Machine Learning (ICML 2015), Interna-
tional Conference on Machine Learning, pages 1093–1102, Lille, France,
2015. URL: http://proceedings.mlr.press/v37/piech15.html.
[36] C. Piech, M. Sahami, J. Huang, and L. Guibas. Autonomously gener-
ating hints by inferring problem solving policies. In G. Kiczales, D. M.
Russel, and B. Woolf, editors, Proceedings of the Second ACM Confer-
ence on Learning @ Scale (L@S 2015), pages 195–204, Vancouver, BC,
Canada, 2015. doi:10.1145/2724660.2724668.
[37] T. W. Price and T. Barnes. An exploration of data-driven hint genera-
tion in an open-ended programming problem. In O. C. Santos, J. G. Bot-
icario, C. Romero, M. Pechenizkiy, A. Merceron, P. Mitros, J. M. Luna,
C. Mihaescu, P. Moreno, A. Hershkovitz, S. Ventura, and M. Desmarais,
editors, Workshops Proceedings of the 8th International Conference on
Educational Data Mining (EDM 2015), Madrid, Spain, 2015. URL:
http://ceur-ws.org/Vol-1446/GEDM_2015_Submission_4.pdf.
[38] T. W. Price, Y. Dong, and T. Barnes. Generating data-driven hints for
open-ended programming. In T. Barnes, M. Chi, and M. Feng, editors,
Proceedings of the 9th International Conference on Educational Data
Mining (EDM 2016), Raleigh, NC, USA, 2016. URL: http://www.
educationaldatamining.org/EDM2016/proceedings/paper_33.pdf.
[39] T. W. Price, Y. Dong, and D. Lipovac. iSnap: Towards intelli-
gent tutoring in novice programming environments. In Proceedings
of the 2017 ACM Technical Symposium on Computer Science Edu-
cation (SIGCSE), pages 483–488, Seattle, Washington, USA, 2017.
doi:10.1145/3017680.3017762.
[40] T. W. Price, R. Zhi, and T. Barnes. Evaluation of a data-driven feedback
algorithm for open-ended programming. In X. Hu, T. Barnes, A. Her-
shkovitz, and L. Paquette, editors, Proceedings of the 10th International
Conference on Educational Datamining (EDM 2017), pages 192–197,
Wuhan, China, 2017. URL: http://educationaldatamining.org/
EDM2017/proc_files/papers/paper_36.pdf.
Preprint as provided by the authors. 49
[41] T. W. Price, R. Zhi, and T. Barnes. Hint generation under uncer-
tainty: The effect of hint quality on help-seeking behavior. In E. André,
R. Baker, X. Hu, M. M. T. Rodrigo, and B. du Boulay, editors, Proceed-
ings of the 18th International Conference on Artificial Intelligence in
Education (AIED 2017), pages 311–322, Wuhan, China, 2017. Springer.
doi:10.1007/978-3-319-61425-0_26.
[42] C. E. Rasmussen and C. K. I. Williams. Gaussian Processes for Ma-
chine Learning (Adaptive Computation and Machine Learning). The
MIT Press, 2005.
[43] K. Rivers and K. R. Koedinger. A canonicalizing model for building pro-
gramming tutors. In S. A. Cerri, W. J. Clancey, G. Papadourakis, and
K. Panourgia, editors, Proceedings of the 11th International Conference
on Intelligent Tutoring Systems, (ITS 2012), pages 591–593, Chania,
Greece, 2012. doi:10.1007/978-3-642-30950-2_80.
[44] K. Rivers and K. R. Koedinger. Data-driven hint generation in vast
solution spaces: a self-improving python programming tutor. Interna-
tional Journal of Artificial Intelligence in Education, 27(1):37–64, 2015.
doi:10.1007/s40593-015-0070-z.
[45] J. C. Stamper, T. Barnes, M. Croy, and M. Eagle. Experimental eval-
uation of automatic hint generation for a logic tutor. International
Journal of Artificial Intelligence in Education, 22(1):3–18, 2012. URL:
http://ijaied.org/pub/1333/.
[46] R. S. Sutton and A. G. Barto. Introduction to Reinforcement Learning.
MIT Press, Cambridge, MA, USA, 1st edition, 1998.
[47] K. Van Lehn. The behavior of tutoring systems. International Journal
of Artificial Intelligence in Education, 16(3):227–265, 2006. URL: http:
//ijaied.org/pub/1063/.
[48] H. Yin, J. Moghadam, and A. Fox. Clustering student programming
assignments to multiply instructor leverage. In Proceedings of the Sec-
ond ACM Conference on Learning @ Scale (L@S 2015), pages 367–372,
Vancouver, BC, Canada, 2015. ACM. doi:10.1145/2724660.2728695.
Preprint as provided by the authors. 50
[49] K. Zhang and D. Shasha. Simple fast algorithms for the editing dis-
tance between trees and related problems. SIAM Journal on Computing,
18(6):1245–1262, 1989. doi:10.1137/0218082.
[50] K. Zimmerman and C. R. Rupakheti. An automated framework for
recommending program elements to novices (n). In Proceedings of
the 30th IEEE/ACM International Conference on Automated Software
Engineering (ASE 2015), pages 283–288, Lincoln, NE, USA, 2015.
doi:10.1109/ASE.2015.54.
